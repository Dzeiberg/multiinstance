{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp likelihoodMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import autograd\n",
    "from autograd import grad,jacobian,hessian\n",
    "from autograd.scipy import stats as agss\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "from scipy.optimize import minimize\n",
    "from glob import glob\n",
    "\n",
    "from multiinstance.likelihoodMethods import *\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.agglomerative_clustering import AgglomerativeClustering\n",
    "\n",
    "os.sched_setaffinity(0,set(range(10,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepDS(dsi):\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=100)\n",
    "\n",
    "    dsi.numLeaves = dsi.alphaHats.shape[0]\n",
    "    dsi.numNodes = dsi.numLeaves + (dsi.numLeaves - 1)\n",
    "    dsi.numInternal = dsi.numNodes - dsi.numLeaves\n",
    "\n",
    "    dsi.mu = np.zeros(dsi.alphaHats.shape[0])\n",
    "    dsi.sigma = np.ones(dsi.numNodes)\n",
    "    dsi.leafN = np.ones_like(dsi.mu) * dsi.alphaHats.shape[1]\n",
    "    dsi.treeAlphaHats = [[] for _ in range(dsi.numNodes)]\n",
    "\n",
    "    for nodeNum in range(dsi.numInternal):\n",
    "        children = getChildren(nodeNum, dsi.numInternal)\n",
    "        leafNums = children - dsi.numInternal\n",
    "        _,unlabeled = list(zip(*[getTransformScores(dsi,n) for n in leafNums]))\n",
    "        pos,_ = list(zip(*[getTransformScores(dsi,n) for n in range(dsi.N)]))\n",
    "        pos = np.concatenate(pos).reshape((-1,1))\n",
    "        unlabeled = np.concatenate(unlabeled).reshape((-1,1))\n",
    "        NEstimates = int(np.sum([dsi.leafN[l] for l in leafNums]))\n",
    "        dsi.treeAlphaHats[nodeNum],_ = getEsts(pos, unlabeled, NEstimates)\n",
    "        _, dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "\n",
    "    for leafNum in range(dsi.numLeaves):\n",
    "        nodeNum = leafNum + dsi.numInternal\n",
    "        dsi.treeAlphaHats[nodeNum] = dsi.alphaHats[leafNum]\n",
    "        dsi.mu[leafNum],dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "    return dsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAlgorithm(dsi):\n",
    "\n",
    "    maes = []\n",
    "    lr = .001\n",
    "\n",
    "    gradNLL_mu = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,dsi.leafN),0)\n",
    "    gradNLL_sigma = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,dsi.leafN),1)\n",
    "    mus = []\n",
    "    sigmas = []\n",
    "    NIter= 1000\n",
    "    for i in tqdm(range(NIter),total=NIter):\n",
    "        if not i % 1500:\n",
    "            lr = lr * .5\n",
    "        deltaMu = gradNLL_mu(dsi.mu,dsi.sigma)\n",
    "        deltaSigma = gradNLL_sigma(dsi.mu,dsi.sigma)\n",
    "        mus.append(dsi.mu)\n",
    "        sigmas.append(dsi.sigma)\n",
    "        dsi.mu = dsi.mu - lr * deltaMu\n",
    "        dsi.sigma = dsi.sigma - lr * deltaSigma\n",
    "        maes.append(np.mean(np.abs(dsi.mu - dsi.trueAlphas.flatten())))\n",
    "    return dsi,mus,sigmas,maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMAE(maes,dsi):\n",
    "    plt.plot(maes,label=\"likelihood method\")\n",
    "    plt.hlines(np.mean(np.abs(dsi.globalAlphaHats.mean() - dsi.trueAlphas.flatten())),\n",
    "               0,len(maes),\n",
    "               color=\"black\",label=\"global\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistrs(ds,mus_):\n",
    "    Nrows = int(np.ceil(np.log2(ds.N))) + 1\n",
    "    fig,ax= plt.subplots(nrows=Nrows,ncols=ds.N,figsize=(5 * ds.N,5 * ds.N))\n",
    "    for row in range(Nrows):\n",
    "        for col in range(2**row):\n",
    "            idx = col\n",
    "            if row > 0:\n",
    "                idx += 2**(row) - 1\n",
    "            ax[row,col].hist(ds.treeAlphaHats[idx],density=True)\n",
    "            children = getChildren(0,1)\n",
    "            leafIndices = getChildren(idx, ds.N - 1).astype(int) - (ds.N-1)\n",
    "            ln = ds.numU[leafIndices]\n",
    "            # Final\n",
    "            mu = np.dot(ds.mu[leafIndices],ln)/np.sum(ln)\n",
    "            sigma = ds.sigma[idx]\n",
    "            pdf = ss.norm.pdf(np.arange(0,1,.01),\n",
    "                              loc=mu,scale=sigma)\n",
    "            ax[row,col].plot(np.arange(0,1,.01),pdf,color=\"green\",alpha=.5)\n",
    "            # Original\n",
    "            mu = np.dot(mus_[0][leafIndices],ln)/np.sum(ln)\n",
    "            sigma = sigmas[0][idx]\n",
    "            pdf = ss.norm.pdf(np.arange(0,1,.01),\n",
    "                              loc=mu,scale=sigma)\n",
    "            ax[row,col].plot(np.arange(0,1,.01),pdf,color=\"red\",alpha=.5)\n",
    "            ax[row,col].set_xlim(0,1)\n",
    "            if row == Nrows - 1:\n",
    "                ax[row,col].vlines(ds.trueAlphas[leafIndices[0]],0,1,color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=10,nU=100,posMean=1,negMean=2,cov=1,alphaDistr=lambda: np.random.choice([.1]))\n",
    "ds2 = buildDataset(1, nP=10,nU=100,posMean=1,negMean=2,cov=1,alphaDistr=lambda: np.random.choice([.8]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi)\n",
    "\n",
    "dsi, mus,sigmas,maes = runAlgorithm(dsi)\n",
    "\n",
    "plotMAE(maes,dsi)\n",
    "\n",
    "plotDistrs(dsi,mus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=1000,nU=10000,posMean=1,negMean=2,cov=1,alphaDistr=lambda: np.random.choice([.1]))\n",
    "ds2 = buildDataset(1, nP=1000,nU=10000,posMean=1,negMean=2,cov=1,alphaDistr=lambda: np.random.choice([.8]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi)\n",
    "\n",
    "dsi, mus,sigmas,maes = runAlgorithm(dsi)\n",
    "\n",
    "plotMAE(maes,dsi)\n",
    "\n",
    "plotDistrs(dsi,mus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderate Number of Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(4,nP=100,nU=1000)\n",
    "dsi = prepDS(dsi)\n",
    "\n",
    "dsi, mus,sigmas,maes = runAlgorithm(dsi)\n",
    "\n",
    "plotMAE(maes,dsi)\n",
    "\n",
    "plotDistrs(dsi,mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

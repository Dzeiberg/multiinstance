{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiinstance.likelihood_method import getChildren, treeNegativeLogLikelihood,runAlgorithm, plotDistrs, plotMAE\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "import scipy.stats as ss\n",
    "\n",
    "from multiinstance.data.realData import buildDataset as buildReal\n",
    "\n",
    "from multiinstance.utils import addTransformScores, addGlobalEsts, getBagAlphaHats,getEsts,getTransformScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export likelihood_method\n",
    "def prepDS(dsi,numbootstraps=10, useAlphaMax=True):\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi,useAlphaMax=useAlphaMax,reps=numbootstraps)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,\n",
    "                                               numbootstraps=numbootstraps,\n",
    "                                               useAlphaMax=useAlphaMax)\n",
    "\n",
    "    dsi.numLeaves = dsi.alphaHats.shape[0]\n",
    "    dsi.numNodes = dsi.numLeaves + (dsi.numLeaves - 1)\n",
    "    dsi.numInternal = dsi.numNodes - dsi.numLeaves\n",
    "    NEstimates = dsi.alphaHats.shape[1]\n",
    "    dsi.mu = np.zeros(dsi.alphaHats.shape[0])\n",
    "    dsi.sigma = np.ones(dsi.numNodes)\n",
    "#     dsi.leafN = np.ones_like(dsi.mu) * dsi.alphaHats.shape[1]\n",
    "    dsi.leafN = dsi.numU\n",
    "    dsi.treeAlphaHats = [[] for _ in range(dsi.numNodes)]\n",
    "\n",
    "    for nodeNum in range(dsi.numInternal):\n",
    "        children = getChildren(nodeNum, dsi.numInternal)\n",
    "        leafNums = children - dsi.numInternal\n",
    "        _,unlabeled = list(zip(*[getTransformScores(dsi,n) for n in leafNums]))\n",
    "        pos,_ = list(zip(*[getTransformScores(dsi,n) for n in range(dsi.N)]))\n",
    "        pos = np.concatenate(pos).reshape((-1,1))\n",
    "        unlabeled = np.concatenate(unlabeled).reshape((-1,1))\n",
    "#         NEstimates = int(np.sum([numEstimates[l] for l in leafNums]))\n",
    "        \n",
    "        dsi.treeAlphaHats[nodeNum],_ = getEsts(pos, unlabeled, NEstimates,useAlphaMax=useAlphaMax)\n",
    "        _, dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "\n",
    "    for leafNum in range(dsi.numLeaves):\n",
    "        nodeNum = leafNum + dsi.numInternal\n",
    "        dsi.treeAlphaHats[nodeNum] = dsi.alphaHats[leafNum]\n",
    "        dsi.mu[leafNum],dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "    return dsi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def posteriorCorrection(tau, alpha, S0S1):\n",
    "    post =  alpha * S0S1 * (tau / (1 - tau))\n",
    "    post[np.isinf(post)] = 1\n",
    "    return post\n",
    "\n",
    "def correctedAUC(ds,bagAlphaHats,):\n",
    "    _, tauArrays = list(zip(*[getTransformScores(ds,i) for i in range(ds.N)]))\n",
    "    S0_S1 = ds.numU/ds.numP\n",
    "    posteriors = [posteriorCorrection(tau,alphaHat, s0s1) for tau,alphaHat,s0s1 in zip(tauArrays,\n",
    "                                                                                       bagAlphaHats,\n",
    "                                                                                       S0_S1)]\n",
    "    posteriorVals = np.concatenate(posteriors)\n",
    "    hiddenLabels = np.concatenate([ds.hiddenLabels[i][:ds.numU[i]] for i in range(ds.N)])\n",
    "    return roc_auc_score(hiddenLabels, posteriorVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fileName,useAlphaMax=False):\n",
    "    dsn = fileName.split(\"/\")[-1].replace(\".mat\",\"\")\n",
    "    dsi = buildReal(fileName,4,\n",
    "                       alphaDistr=lambda: np.random.uniform(.05,.95),\n",
    "                      nPDistr=lambda: 1 + np.random.poisson(25),\n",
    "                      nUDistr=lambda: 1 + np.random.poisson(75))\n",
    "    dsi = prepDS(dsi,numbootstraps=25,useAlphaMax=useAlphaMax)\n",
    "    dsi, mus,sigmas,maes,NLL = runAlgorithm(dsi,\n",
    "                                            NIter=2500,\n",
    "                                            rlambda=1,)\n",
    "    localAE = maes[0] * dsi.N\n",
    "    likelihoodAE = maes[-1] * dsi.N\n",
    "    globalAE = np.abs(dsi.globalAlphaHats.mean() - dsi.trueAlphas.flatten()).sum()\n",
    "    maeFig = plotMAE(maes,dsi)\n",
    "    plt.show()\n",
    "    dstrFig = plotDistrs(dsi,mus,sigmas)\n",
    "    plt.show()\n",
    "    nllFig,ax= plt.subplots()\n",
    "    ax.plot(NLL)\n",
    "    plt.show()\n",
    "    if useAlphaMax:\n",
    "        mode = \"alphamax\"\n",
    "    else:\n",
    "        mode = \"distcurve\"\n",
    "    maeFig.savefig(\"figs/nb_24/{}_{}_mae.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    nllFig.savefig(\"figs/nb_24/{}_{}_nll.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    dstrFig.savefig(\"figs/nb_24/{}_{}_distr.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    return localAE, globalAE, likelihoodAE,dsi.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fileName,numbags=16, numbootstraps=25,useAlphaMax=False, meanPosSize=10, meanUnlabeledSize=20,NIter=1000):\n",
    "    dsn = fileName.split(\"/\")[-1].replace(\".mat\",\"\")\n",
    "    dsi = buildReal(fileName,numbags,\n",
    "                       alphaDistr=lambda: np.random.uniform(.05,.95),\n",
    "                      nPDistr=lambda: 1 + np.random.poisson(meanPosSize),\n",
    "                      nUDistr=lambda: 1 + np.random.poisson(meanUnlabeledSize))\n",
    "    dsi = prepDS(dsi,numbootstraps=numbootstraps,useAlphaMax=useAlphaMax)\n",
    "    dsi, mus,sigmas,maes,NLL = runAlgorithm(dsi,\n",
    "                                            NIter=NIter,\n",
    "                                            rlambda=1,)\n",
    "    localAE = maes[0] * dsi.N\n",
    "    likelihoodAE = maes[-1] * dsi.N\n",
    "    globalAE = np.abs(dsi.globalAlphaHats.mean() - dsi.trueAlphas.flatten()).sum()\n",
    "    localAUC = correctedAUC(dsi, mus[0])\n",
    "    likelihoodAUC = correctedAUC(dsi,mus[-1])\n",
    "    globalAUC = correctedAUC(dsi,np.ones(dsi.N)*dsi.globalAlphaHats.mean())\n",
    "    maeFig = plotMAE(maes,dsi)\n",
    "    plt.show()\n",
    "    dstrFig = plotDistrs(dsi,mus,sigmas)\n",
    "    plt.show()\n",
    "    nllFig,ax= plt.subplots()\n",
    "    ax.plot(NLL)\n",
    "    plt.show()\n",
    "    if useAlphaMax:\n",
    "        mode = \"alphamax\"\n",
    "    else:\n",
    "        mode = \"distcurve\"\n",
    "    maeFig.savefig(\"figs/nb_24/{}_{}_mae.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    nllFig.savefig(\"figs/nb_24/{}_{}_nll.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    dstrFig.savefig(\"figs/nb_24/{}_{}_distr.pdf\".format(dsn,mode),format=\"pdf\")\n",
    "    return localAE, globalAE, likelihoodAE,dsi.N, localAUC, likelihoodAUC, globalAUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moderate Sized Bags\n",
    "Alphamax is clearly inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileNames = glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")\n",
    "fileNames = glob(\"/ssdata/ClassPriorEstimationPrivate/data/rawDatasets/*.mat\")\n",
    "absErrs = {\"distcurve\":{\"local\":0,\n",
    "           \"global\":0,\n",
    "           \"likelihood\":0},\n",
    "           \"alphamax\":{\"local\":0,\n",
    "           \"global\":0,\n",
    "           \"likelihood\":0}}\n",
    "N = 0\n",
    "for fileName in tqdm(fileNames,total=len(fileNames)):\n",
    "    print(fileName)\n",
    "    # RUN DISTCURVE\n",
    "    print(\"DistCurve\")\n",
    "    localAE, globalAE, likelihoodAE,ni,localAUC,likelihoodAUC,globalAUC = run(fileName, useAlphaMax=False)\n",
    "    # Log Results\n",
    "    N += ni\n",
    "    absErrs[\"distcurve\"][\"local\"] += localAE\n",
    "    absErrs[\"distcurve\"][\"global\"] += globalAE\n",
    "    absErrs[\"distcurve\"][\"likelihood\"] += likelihoodAE\n",
    "    for k,v in absErrs[\"distcurve\"].items():\n",
    "        print(k, \"{:.3f}\".format(v/N))\n",
    "    # AlphaMax\n",
    "    print(\"Alphamax\")\n",
    "    localAE, globalAE, likelihoodAE,_ = run(fileName, useAlphaMax=True)\n",
    "    # Log Results\n",
    "    absErrs[\"alphamax\"][\"local\"] += localAE\n",
    "    absErrs[\"alphamax\"][\"global\"] += globalAE\n",
    "    absErrs[\"alphamax\"][\"likelihood\"] += likelihoodAE\n",
    "    for k,v in absErrs[\"alphamax\"].items():\n",
    "        print(k, \"{:.3f}\".format(v/N))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".014 / .094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileNames = glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")\n",
    "fileNames = glob(\"/ssdata/ClassPriorEstimationPrivate/data/rawDatasets/*.mat\")\n",
    "absErrs = {\"distcurve\":{\"local\":0,\n",
    "           \"global\":0,\n",
    "           \"likelihood\":0}}\n",
    "aucs = {\"distcurve\":{\"local\":[],\n",
    "           \"global\":[],\n",
    "           \"likelihood\":[]}}\n",
    "N = 0\n",
    "for fileName in tqdm(fileNames,total=len(fileNames)):\n",
    "    print(fileName)\n",
    "    # RUN DISTCURVE\n",
    "    print(\"DistCurve\")\n",
    "    localAE, globalAE, likelihoodAE,ni,localAUC,likelihoodAUC,globalAUC = run(fileName,\n",
    "                                                                              useAlphaMax=False,\n",
    "                                                                              numbags=16,\n",
    "                                                                              numbootstraps=100,\n",
    "                                                                              NIter=2500,\n",
    "                                                                              meanPosSize=125,\n",
    "                                                                              meanUnlabeledSize=175)\n",
    "    # Log Results\n",
    "    N += ni\n",
    "    absErrs[\"distcurve\"][\"local\"] += localAE\n",
    "    absErrs[\"distcurve\"][\"global\"] += globalAE\n",
    "    absErrs[\"distcurve\"][\"likelihood\"] += likelihoodAE\n",
    "    aucs[\"distcurve\"][\"local\"].append(localAUC)\n",
    "    aucs[\"distcurve\"][\"likelihood\"].append(likelihoodAUC)\n",
    "    aucs[\"distcurve\"][\"global\"].append(globalAUC)\n",
    "    print(\"MAE\")\n",
    "    for k,v in absErrs[\"distcurve\"].items():\n",
    "        print(k, \"{:.3f}\".format(v/N))\n",
    "    print(\"AUC\")\n",
    "    for k,v in aucs[\"distcurve\"].items():\n",
    "        print(k, \"{:.3f}\".format(np.mean(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileNames = glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")\n",
    "fileNames = glob(\"/ssdata/ClassPriorEstimationPrivate/data/rawDatasets/*.mat\")\n",
    "absErrs = {\"distcurve\":{\"local\":0,\n",
    "           \"global\":0,\n",
    "           \"likelihood\":0}}\n",
    "aucs = {\"distcurve\":{\"local\":[],\n",
    "           \"global\":[],\n",
    "           \"likelihood\":[]}}\n",
    "N = 0\n",
    "for fileName in tqdm(fileNames,total=len(fileNames)):\n",
    "    print(fileName)\n",
    "    # RUN DISTCURVE\n",
    "    print(\"DistCurve\")\n",
    "    localAE, globalAE, likelihoodAE,ni,localAUC,likelihoodAUC,globalAUC = run(fileName,\n",
    "                                                                              useAlphaMax=False,\n",
    "                                                                              numbags=16,\n",
    "                                                                              numbootstraps=100,\n",
    "                                                                              NIter=2500,\n",
    "                                                                              meanPosSize=125,\n",
    "                                                                              meanUnlabeledSize=175)\n",
    "    # Log Results\n",
    "    N += ni\n",
    "    absErrs[\"distcurve\"][\"local\"] += localAE\n",
    "    absErrs[\"distcurve\"][\"global\"] += globalAE\n",
    "    absErrs[\"distcurve\"][\"likelihood\"] += likelihoodAE\n",
    "    aucs[\"distcurve\"][\"local\"].append(localAUC)\n",
    "    aucs[\"distcurve\"][\"likelihood\"].append(likelihoodAUC)\n",
    "    aucs[\"distcurve\"][\"global\"].append(globalAUC)\n",
    "    print(\"MAE\")\n",
    "    for k,v in absErrs[\"distcurve\"].items():\n",
    "        print(k, \"{:.3f}\".format(v/N))\n",
    "    print(\"AUC\")\n",
    "    for k,v in aucs[\"distcurve\"].items():\n",
    "        print(k, \"{:.3f}\".format(np.mean(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 bags 10 P, 20 U alpha~U(.05,.95)\n",
    "\n",
    "MAE\n",
    "local 0.211\n",
    "global 0.239\n",
    "likelihood 0.195\n",
    "AUC\n",
    "local 0.743\n",
    "global 0.767\n",
    "likelihood 0.747"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 Bags 125P 175U alpha~U(.05,.95)\n",
    "\n",
    "MAE\n",
    "local 0.056\n",
    "global 0.227\n",
    "likelihood 0.055\n",
    "AUC\n",
    "local 0.952\n",
    "global 0.936\n",
    "likelihood 0.951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(.175-.153) / .175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

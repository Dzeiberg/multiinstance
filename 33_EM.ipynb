{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "from easydict import EasyDict\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import roc_auc_score,adjusted_mutual_info_score, adjusted_rand_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bag$_i$**\n",
    "\n",
    "\n",
    "**latent positive class conditional distribution**\n",
    "* $z_k = 1$ indicates instance came from component k\n",
    "\n",
    "$p^i(z_k = 1 | y=1) = \\pi^i_k$\n",
    "\n",
    "**latent negative class conditional distribution**\n",
    "\n",
    "$p^i(z_k=1 | y=0) = \\rho^i_k$\n",
    "\n",
    "**latent positive posterior distribution**\n",
    "\n",
    "$ p(z_k=1|x, y=1) = \\gamma(z_k) = \\frac{\\pi^i_k \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k)}{\\sum_{j=1}^{K_1} \\pi^i_j \\phi^1_j(x;\\mu^1_j,\\Sigma^1_j)} $\n",
    "\n",
    "**positive class conditional distribution**\n",
    "* K-component gaussian mixture model\n",
    "* components shared across bags\n",
    "* mixture weights unique to each bag\n",
    "\n",
    "$p^i(x|y=1) = \\sum_{k=1}^{K_1} \\pi^i_k \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k)$\n",
    "\n",
    "**marginal distribution**\n",
    "\n",
    "$p(x|b_i) = p(y=1|b_i)p(x|y=1,b_i) + p(y=0|b_i)p(x|y=0,b_i)$\n",
    "\n",
    "$p^i(x) =\\alpha_i \\sum_{k=1}^{K_1} \\pi^i_k \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k) + (1-\\alpha_i) \\sum_{k=1}^{K_0}\\rho^i_k \\phi^0_k(x;\\mu^0_k;\\Sigma^0_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag$_i \\cup$ Bag$_j$\n",
    "\n",
    "$p(x)= w_i [(\\alpha_i \\sum_{k=1}^{K_1} \\pi^i_k \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k) + (1-\\alpha_i) \\sum_{k=1}^{K_0}\\rho^i_k \\phi^0_k(x;\\mu^0_k;\\Sigma^0_k))] + w_j[\\alpha_j \\sum_{k=1}^{K_1} \\pi^j_k \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k) + (1-\\alpha_j) \\sum_{k=1}^{K_0}\\rho^j_k \\phi^0_k(x;\\mu^0_k;\\Sigma^0_k)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Bags\n",
    "* $b_i := \\{c_i,m_i\\}$ : bag with component and mixture sample \n",
    "* B : set of bags {$b_i$}\n",
    "* positive bag weight : $w^1_i = \\frac{|c_i|}{\\sum_{j\\in B} |c_j|}$\n",
    "* unlabeled bag weight : $w^0_i = \\frac{|m_i|}{\\sum_{j\\in B} |m_j|}$\n",
    "\n",
    "**Positive Latent Marginal**\n",
    "\n",
    "$ p(z_k = 1|y=1) = \\sum_{i=1}^{|B|} p(b_i)p(z_k=1|b_i,y=1) = \\sum_{i=1}^{|B|} w_i \\pi_k^i = \\pi_k^B$\n",
    "\n",
    "**Positive conditional latent posterior**\n",
    "\n",
    "$p(z_k=1|x,y=1) = \\gamma^B(z_k) = \\frac{\\pi_k^B \\phi_k(x)}{\\sum_{j=1}^K \\pi_j^B \\phi_j(x))}$\n",
    "\n",
    "**Positive Class Conditional Distribution**\n",
    "\n",
    "$p(x|y=1) = \\sum_{k=1}^{K_1} p(z_k=1 | y=1)p(x|z_k=1,y=1) = \\sum_{k=1}^{K_1}(\\sum_{i=1}^{|B|} w^1_i \\pi^i_k) \\phi^1_k(x;\\mu^1_k,\\Sigma^1_k)$\n",
    "\n",
    "**Marginal Distribution**\n",
    "\n",
    "$p(x) = \\sum_{k=1}^{K_1} (\\sum_{i=1}^{|B|}w^0_i \\alpha_i \\pi_k^i) \\phi_k^1(x|\\mu^1_k,\\Sigma^1_k) + \\sum_{k=1}^{K_0}(\\sum_{i=1}^{|B|}w_i^0 (1-\\alpha_i)\\rho_k^i)\\phi^0_k(x;\\mu^0_k,\\Sigma^0_k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeansInit(X, k):\n",
    "    means = [X[np.random.choice(np.arange(X.shape[0]))]]\n",
    "    for iteration in range(k-1):\n",
    "        dists = cdist(X, np.stack(means)).min(1)\n",
    "        probs = dists / dists.sum()\n",
    "        nextIndex = np.random.choice(np.arange(X.shape[0]),p=probs)\n",
    "        means.append(X[nextIndex])\n",
    "    return np.stack(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM:\n",
    "    def __init__(self, X, k):\n",
    "        self.X = X\n",
    "        self.k = k\n",
    "        self.N,self.dim = self.X.shape\n",
    "        self.initializeComponents()\n",
    "        \n",
    "    def initializeComponents(self):\n",
    "        mins = self.X.min(0)\n",
    "        maxs = self.X.max(0)\n",
    "        # USE K-MEANS++\n",
    "#         self.mus = KMeansInit(self.X, self.k)\n",
    "        self.mus = self.X[np.random.choice(np.arange(self.X.shape[0]),size=self.k)]\n",
    "        self.covs = np.stack([np.eye(self.dim) for _ in range(self.k)])\n",
    "        self.pi = np.random.dirichlet(np.ones(self.k))\n",
    "        \n",
    "    def E_Step(self):\n",
    "        gammas = np.zeros((self.N,self.k))\n",
    "        for n in range(self.N):\n",
    "            for k in range(self.k):\n",
    "                gammas[n,k] = self.pi[k] * ss.multivariate_normal.pdf(self.X[n],\n",
    "                                                                      mean=self.mus[k],\n",
    "                                                                      cov=self.covs[k])\n",
    "            gammas[n] = gammas[n] / gammas[n].sum()\n",
    "        self.gammas = gammas\n",
    "        \n",
    "    def M_Step(self):\n",
    "        Nk = np.sum(self.gammas, axis=0)[:,np.newaxis]\n",
    "        self.mus = np.dot(self.gammas.T, self.X) / Nk\n",
    "        self.pi = np.mean(self.gammas,axis=0)\n",
    "        for k in range(self.k):\n",
    "            x = np.matrix(self.X - self.mus[k,:])\n",
    "            gamma_diag = np.matrix(np.diag(self.gammas[:,k]))\n",
    "            sigma_k = x.T * gamma_diag * x\n",
    "            self.covs[k,:,:] = sigma_k / Nk[k]\n",
    "            \n",
    "            \n",
    "    def log_likelihood(self):\n",
    "        ll = 0\n",
    "        for xn in self.X:\n",
    "            ll += np.log(np.sum([pik * ss.multivariate_normal.pdf(xn,\n",
    "                                                                  mean=muk,\n",
    "                                                                  cov=covk) for pik,muk,covk in zip(self.pi,\n",
    "                                                                                                    self.mus,\n",
    "                                                                                                    self.covs)]))\n",
    "        return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "Ys = []\n",
    "weights = []\n",
    "N = 200\n",
    "for _ in range(10):\n",
    "    n = np.random.dirichlet((5,5,5))\n",
    "    weights.append(n)\n",
    "    Xs.append(np.concatenate((np.random.multivariate_normal([2,2],\n",
    "                                                           np.eye(2),\n",
    "                                                           size=int(N*n[0])),\n",
    "                             np.random.multivariate_normal([-2,-1],\n",
    "                                                           np.eye(2),\n",
    "                                                           size=int(N*n[1])),\n",
    "                             np.random.multivariate_normal([2,-2],\n",
    "                                                           np.eye(2),\n",
    "                                                           size=int(N*n[2])))))\n",
    "    Ys.append(np.concatenate((np.ones(int(N*n[0])),\n",
    "                              np.zeros(int(N*n[1])),\n",
    "                              np.ones(int(N * n[2])) * -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aris1 = []\n",
    "for xi,yi in zip(Xs,Ys):\n",
    "    em = EM(xi,3)\n",
    "    for _ in range(100):\n",
    "        em.E_Step()\n",
    "        em.M_Step()\n",
    "\n",
    "    ax = plt.subplot(111, aspect='equal')\n",
    "    for comp in range(em.k):\n",
    "        lambda_, v = np.linalg.eig(em.covs[comp])\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "\n",
    "        ell = matplotlib.patches.Ellipse(xy=em.mus[comp],\n",
    "                          width=lambda_[0]*2*2, height=lambda_[1]*2*2,\n",
    "                          angle=np.rad2deg(np.arccos(v[0, 0])),alpha=.5)\n",
    "        #     ell.set_facecolor('none')\n",
    "        ax.add_artist(ell)\n",
    "    ax.scatter(em.X[:,0],em.X[:,1],color=\"green\",alpha=.5)\n",
    "    plt.show()\n",
    "    aris1.append(adjusted_rand_score(yi,np.argmax(em.gammas,axis=1)))\n",
    "print(np.mean(aris1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = [EM(xi,3) for xi in Xs]\n",
    "NIters = 25\n",
    "aris = []\n",
    "LLs = np.zeros((NIters,len(Xs)))\n",
    "for iteration in range(NIters):\n",
    "    for i in range(len(Xs)):\n",
    "        LLs[iteration,i] = ems[i].log_likelihood()\n",
    "        ems[i].E_Step()\n",
    "        ems[i].M_Step()\n",
    "        ems[(i+1) % len(Xs)].mus = ems[i].mus\n",
    "        ems[(i+1) % len(Xs)].covs = ems[i].covs\n",
    "# After final iteration, update all out-of-date copies of mus and covs and also gamma \n",
    "for j in range(1,len(Xs)-1):\n",
    "    ems[j].mus = ems[0].mus\n",
    "    ems[j].covs = ems[0].covs\n",
    "    # update gamma with new mus and covs values\n",
    "    ems[j].E_Step()\n",
    "# Calculate performance\n",
    "for em,yi in zip(ems, Ys):\n",
    "    aris.append(adjusted_rand_score(yi,np.argmax(em.gammas,axis=1)))\n",
    "print(np.mean(aris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "for i in range(len(Xs)):\n",
    "    ax.plot(LLs[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,len(Xs),figsize=(4 * len(Xs),4),sharey=True, sharex=True)\n",
    "for ds_num in range(len(Xs)):\n",
    "    for comp in range(ems[ds_num].k):\n",
    "        lambda_, v = np.linalg.eig(ems[ds_num].covs[comp])\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "\n",
    "        ell = matplotlib.patches.Ellipse(xy=ems[ds_num].mus[comp],\n",
    "                          width=lambda_[0]*2*2, height=lambda_[1]*2*2,\n",
    "                          angle=np.rad2deg(np.arccos(v[0, 0])),alpha=.5)\n",
    "        ax[ds_num].add_artist(ell)\n",
    "    ax[ds_num].scatter(ems[ds_num].X[:,0],ems[ds_num].X[:,1],alpha=.5,color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Description\n",
    "Here, I test whether a multi-instance clustering approach can lead to better estimates of the latent cluster assignment than separate clustering processes. While Shantanu and I thought we should compare the resulting mixing proportions, I think comparing the cluster predictions derived from the latent posterior more directly compares the values of interest. I use the [adjusted rand index](https://en.wikipedia.org/wiki/Rand_index) to compare the quality of the clusterings of the two methods.\n",
    "\n",
    "As seen in the above experiments, the average adjusted rand index across all bags is higher when using the multi-instance clustering approach. Further, the multi-instance method ensures the estimated distributions $\\phi_k$ are the same for each bag. I do not evaluate the quality of the resulting distributions and believe the quality of the gaussians degrades in high dimensions.\n",
    "\n",
    "**Notes**\n",
    "* I'm not directly comparing the quality of the latent posterior but rather the clustering estimates that those posteriors lead to\n",
    "* I'm treating this evaluation as an alternative to separately comparing the quality of the latent marginal (r$^i_j$ i.e. p(z = k) ) and the fitted distributions $\\phi_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEM:\n",
    "    def __init__(self, bags, n_components,KMeansPPInit=True):\n",
    "        self.em_instances = []\n",
    "        self.labels = []\n",
    "        self.bags = bags\n",
    "        # Initialize each EM instance\n",
    "        for bag in self.bags:\n",
    "            self.em_instances.append(EM(bag.X_pos, n_components))\n",
    "        # Override the initialization\n",
    "        if KMeansPPInit:\n",
    "            self.em_instances[0].mus = KMeansInit(np.concatenate([e.X for e in self.em_instances]),\n",
    "                                                  n_components)\n",
    "    def run_positive_em(self, n_iters, multi=True):\n",
    "        self.logLikelihoods = np.zeros((len(self.em_instances),\n",
    "                                        n_iters+2))\n",
    "        for inst in range(len(self.em_instances)):\n",
    "            self.logLikelihoods[inst,0] = self.em_instances[inst].log_likelihood()\n",
    "        for iteration in tqdm(range(1, n_iters+1),total=n_iters,leave=False):\n",
    "            for inst in range(len(self.em_instances)):\n",
    "                self.em_instances[inst].E_Step()\n",
    "                self.em_instances[inst].M_Step()\n",
    "                if multi:\n",
    "                    self.em_instances[(inst+1) % len(self.em_instances)].mus = self.em_instances[inst].mus\n",
    "                    self.em_instances[(inst+1) % len(self.em_instances)].covs = self.em_instances[inst].covs\n",
    "                self.logLikelihoods[inst,iteration] = self.em_instances[inst].log_likelihood()\n",
    "        # After final iteration, pass mu and cov to all instances and update gammas through the E_Step\n",
    "        for j in range(len(self.em_instances)):\n",
    "            if multi:\n",
    "                self.em_instances[j].mus = self.em_instances[0].mus\n",
    "                self.em_instances[j].covs = self.em_instances[0].covs\n",
    "                # update gamma with new mus and covs values\n",
    "                self.em_instances[j].E_Step()\n",
    "            self.logLikelihoods[j, -1] = self.em_instances[j].log_likelihood()\n",
    "        self.compute_positive_clustering_performance()\n",
    "\n",
    "    def compute_positive_clustering_performance(self):\n",
    "        adjusted_rand_scores = []\n",
    "        for em,bag in zip(self.em_instances, self.bags):\n",
    "            adjusted_rand_scores.append(adjusted_rand_score(bag.positive_component_labels,\n",
    "                                                            np.argmax(em.gammas,axis=1)))\n",
    "        self.score = np.mean(adjusted_rand_scores)\n",
    "\n",
    "    def cluster_unlabeled(self):\n",
    "        for bagnum, (bag, em) in enumerate(zip(self.bags, self.em_instances)):\n",
    "            assignments = np.zeros(bag.x_unlabeled.shape[0]).astype(int)\n",
    "            for instnum,inst in enumerate(bag.x_unlabeled):\n",
    "                lls = np.zeros(em.k)\n",
    "                for i,(mu,cov) in enumerate(zip(em.mus, em.covs)):\n",
    "                    lls[i] = ss.multivariate_normal.logpdf(inst,mean=mu,cov=cov)\n",
    "                assignments[instnum] = np.argmax(lls)\n",
    "            self.bags[bagnum].unlabeled_assignments = assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvn_gen(mean):\n",
    "    return lambda n: np.random.multivariate_normal(mean, np.eye(len(mean)),size=n)\n",
    "\n",
    "def generateBags(NBags,\n",
    "                 NPos=200,\n",
    "                 NUnlabeled=1000,\n",
    "                 pos_means=[[2,2], [-2,-2], [2,-2]],\n",
    "                 neg_means=[[0,0]]):\n",
    "    bags = []\n",
    "    pos_components = [mvn_gen(m) for m in pos_means]\n",
    "    neg_components = [mvn_gen(m) for m in neg_means]\n",
    "    for _ in range(NBags):\n",
    "        pos_weights = np.random.dirichlet(np.ones(len(pos_components))*5)\n",
    "        bag = EasyDict()\n",
    "        bag.pi = pos_weights\n",
    "        bag.pos_weights = pos_weights\n",
    "        x = []\n",
    "        positive_component_labels = []\n",
    "        for i,(comp,w) in enumerate(zip(pos_components,pos_weights)):\n",
    "            ni = np.round(NPos * w).astype(int)\n",
    "            x.append(comp(ni))\n",
    "            positive_component_labels.append(np.ones(ni) * i)\n",
    "        bag.X_pos = np.concatenate(x)\n",
    "        bag.positive_component_labels = np.concatenate(positive_component_labels)\n",
    "        alpha = np.random.beta(2,2)\n",
    "        bag.alpha = alpha\n",
    "        n_unlabeled_pos = np.round(NUnlabeled * alpha).astype(int)\n",
    "        n_unlabeled_neg = NUnlabeled - n_unlabeled_pos\n",
    "        xunlabeled = []\n",
    "        unlabeled_pos_componenet_labels = []\n",
    "        for i,(comp,w) in enumerate(zip(pos_components,pos_weights)):\n",
    "            ni = np.round(n_unlabeled_pos * w).astype(int)\n",
    "            xunlabeled.append(comp(ni))\n",
    "            unlabeled_pos_componenet_labels.append(np.ones(ni) * i)\n",
    "        bag.unlabeled_pos_componenet_labels = unlabeled_pos_componenet_labels\n",
    "        unlabeled_neg_weights = np.random.dirichlet(np.ones(len(neg_components)) * 5)\n",
    "        bag.rho = unlabeled_neg_weights\n",
    "        unlabeled_neg_componenet_labels = []\n",
    "        for i, (comp,w) in enumerate(zip(neg_components, unlabeled_neg_weights)):\n",
    "            ni = np.round(n_unlabeled_neg * w).astype(int)\n",
    "            xunlabeled.append(comp(ni))\n",
    "            unlabeled_neg_componenet_labels.append(np.ones(ni) * i)\n",
    "        bag.unlabeled_neg_componenet_labels = unlabeled_neg_componenet_labels\n",
    "        bag.x_unlabeled = np.concatenate(xunlabeled)\n",
    "        bags.append(bag)\n",
    "    return bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags = generateBags(100,NPos=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = MultiEM(bags,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem.run_positive_em(10, multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aes = []\n",
    "bce = []\n",
    "for em, bag in zip(mem.em_instances, mem.bags):\n",
    "    aes.append(np.abs(em.pi - bag.pi))\n",
    "    bce.append(np.sum(-1 * bag.pi * np.log(em.pi)))\n",
    "print(\"pi_k MAE: {:.3f}\\nBCE: {:.3f}\".format(np.mean(aes), np.mean(bce)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem2 = MultiEM(bags,3,KMeansPPInit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem2.run_positive_em(10, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aes2 = []\n",
    "bce2= []\n",
    "for em, bag in zip(mem2.em_instances, mem2.bags):\n",
    "    aes2.append(np.abs(em.pi - bag.pi))\n",
    "    bce2.append(np.sum(-1 * bag.pi * np.log(em.pi)))\n",
    "print(\"pi_k MAE: {:.3f}\\nBCE: {:.3f}\".format(np.mean(aes2), np.mean(bce2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem2.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem3 = MultiEM(bags,3,KMeansPPInit=False)\n",
    "mem3.run_positive_em(10,multi=True)\n",
    "aes3 = []\n",
    "bce3= []\n",
    "for em, bag in zip(mem3.em_instances, mem3.bags):\n",
    "    aes3.append(np.abs(em.pi - bag.pi))\n",
    "    bce3.append(np.sum(-1 * bag.pi * np.log(em.pi)))\n",
    "print(\"pi_k MAE: {:.3f}\\nBCE: {:.3f}\".format(np.mean(aes3), np.mean(bce3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem3.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in mem.logLikelihoods:\n",
    "    plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in mem2.logLikelihoods:\n",
    "    plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,len(mem.bags),figsize=(4 * len(mem.bags),4),sharey=True, sharex=True)\n",
    "for ds_num in range(len(mem.bags)):\n",
    "    for comp in range(mem.em_instances[ds_num].k):\n",
    "        lambda_, v = np.linalg.eig(mem.em_instances[ds_num].covs[comp])\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "\n",
    "        ell = matplotlib.patches.Ellipse(xy=mem.em_instances[ds_num].mus[comp],\n",
    "                          width=lambda_[0]*2*2, height=lambda_[1]*2*2,\n",
    "                          angle=np.rad2deg(np.arccos(v[0, 0])),alpha=.5)\n",
    "        ax[ds_num].add_artist(ell)\n",
    "        # separate\n",
    "        lambda_, v = np.linalg.eig(mem2.em_instances[ds_num].covs[comp])\n",
    "        lambda_ = np.sqrt(lambda_)\n",
    "\n",
    "        ell = matplotlib.patches.Ellipse(xy=mem2.em_instances[ds_num].mus[comp],\n",
    "                          width=lambda_[0]*2*2, height=lambda_[1]*2*2,\n",
    "                          angle=np.rad2deg(np.arccos(v[0, 0])),alpha=.25,color=\"red\")\n",
    "        ax[ds_num].add_artist(ell)\n",
    "        # done\n",
    "    ax[ds_num].scatter(mem.bags[ds_num].X_pos[:,0],\n",
    "                       mem.bags[ds_num].X_pos[:,1],alpha=.5,color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ward_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.distanceApproaches import *\n",
    "from multiinstance.data.syntheticData import buildDataset,getBag\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from numba import set_num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_num_threads(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class WardClustering:\n",
    "    def __init__(self, dsi):\n",
    "        self.clusterAssignment = np.zeros((dsi.N, dsi.N))\n",
    "        self.clusterAssignment[0] = np.arange(dsi.N)\n",
    "        self.clusterAlphaHats = {i: dsi.alphaHats[i] for i in range(dsi.N)}\n",
    "        self.ds = dsi\n",
    "        self.meanAbsErrs = np.zeros(dsi.N)\n",
    "        self.deltas = np.zeros(dsi.N - 1)\n",
    "        self.doLogging(0)\n",
    "        self.log = []\n",
    "        \n",
    "    def doLogging(self, c_iter):\n",
    "#         print(\"logging \",c_iter)\n",
    "        absErrs = []\n",
    "        clusters = np.unique(self.clusterAssignment[c_iter])\n",
    "#         print(self.clusterAssignment)\n",
    "        for ci in clusters:\n",
    "            bags = np.where(self.clusterAssignment[c_iter] == ci)[0]\n",
    "#             print(bags)\n",
    "            aHat = self.clusterAlphaHats[ci].mean()\n",
    "            alphas = self.ds.trueAlphas[bags].flatten()\n",
    "            # log abs. err for this cluster\n",
    "            aes = np.abs(alphas - aHat)\n",
    "            absErrs.append(aes)\n",
    "        self.meanAbsErrs[c_iter] = np.mean(np.concatenate(absErrs))\n",
    "#         print(\"MAE after \",c_iter,\" merges: \",self.meanAbsErrs)\n",
    "    \n",
    "    def cluster(self):\n",
    "        for c_iter in tqdm(range(1, self.ds.N),desc=\"clustering iter\",total=self.ds.N-1):\n",
    "            clusters = np.unique(self.clusterAssignment[c_iter - 1])\n",
    "            Nc = len(clusters)\n",
    "            deltas = np.ones((Nc, Nc))\n",
    "            alphaHats_Merged_Clusters = np.zeros((Nc,Nc, 10))\n",
    "            for i, ci in tqdm(enumerate(clusters), desc=\"ci\", total=Nc, leave=False):\n",
    "                alphaHat_ci = self.clusterAlphaHats[ci]\n",
    "                var_ci = np.sum((alphaHat_ci - alphaHat_ci.mean())**2)\n",
    "                for j, cj in enumerate(set(clusters)):\n",
    "                    if i != j:\n",
    "                        alphaHat_cj = self.clusterAlphaHats[cj]\n",
    "                        var_cj = np.sum((alphaHat_cj - alphaHat_cj.mean())**2)\n",
    "                        # alpha hats from i or j\n",
    "                        alphaHats = np.concatenate((alphaHat_ci,\n",
    "                                                       alphaHat_cj))\n",
    "                        # Get alphaHat for joint cluster\n",
    "                        bagIdxs = np.where(np.isin(self.clusterAssignment[c_iter - 1],[ci,cj]))[0]\n",
    "                        alphaHat_cij = self.getClusterEst(bagIdxs)\n",
    "                        alphaHats_Merged_Clusters[i,j] = alphaHat_cij\n",
    "                        var_cij = np.sum((alphaHats - alphaHat_cij.mean())**2)\n",
    "                        deltas[i,j]= var_cij - var_ci - var_cj\n",
    "            # find indices of bags to merge\n",
    "            idx = np.argmin(deltas)\n",
    "            i,j = int(idx / deltas.shape[0]), idx % deltas.shape[0]\n",
    "            ci, cj = clusters[i], clusters[j]\n",
    "#             print(deltas)\n",
    "            self.log.append((ci,cj))\n",
    "            # deltas i indexed list of increase in cluster variance caused by the i+1_th merge\n",
    "            self.deltas[c_iter - 1] = deltas[i,j]\n",
    "            # set cluster assignment after this merge\n",
    "            self.clusterAssignment[c_iter] = self.clusterAssignment[c_iter - 1]\n",
    "            inJ = np.where(self.clusterAssignment[c_iter] == cj)[0]\n",
    "            self.clusterAssignment[c_iter, inJ] = ci\n",
    "            # update the alphaHat to that estimated from the newly formed cluster\n",
    "            self.clusterAlphaHats[ci] = alphaHats_Merged_Clusters[i,j]\n",
    "            self.doLogging(c_iter)\n",
    "\n",
    "    def getClusterEst(self,bagIdxs):\n",
    "        P,U = list(zip(*[self.ds.getBag(b) for b in bagIdxs]))\n",
    "        p = np.concatenate(P)\n",
    "        u = np.concatenate(U)\n",
    "        alphaHats, _ = getEsts(p,u,10)\n",
    "        return alphaHats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(10,alphaDistr=lambda: np.random.uniform(.01,.5),\n",
    "                  nP=10,nU=25)\n",
    "\n",
    "dsi = addTransformScores(dsi)\n",
    "\n",
    "dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward = WardClustering(dsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(2,1, sharex=True)\n",
    "ax[0].plot(ward.meanAbsErrs)\n",
    "ax[1].plot(np.arange(1, len(ward.deltas) + 1), ward.deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

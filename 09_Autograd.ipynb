{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gradientMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Based Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\alpha_i}$: the local dictCurve estimate for the $i^{th}$ bag\n",
    "\n",
    "$\\hat{\\alpha_{c_i}}$: the $i^{th}$ global distCurve estimate using bootstrapped sample\n",
    "\n",
    "$w_{ji}$: the contribution of bag j to the $i^{th}$ global estimate\n",
    "\n",
    "$\\tilde{\\alpha_i}$: the expected global class prior given the current contribution values and local estimates for each bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tilde{\\alpha_i} = \\frac{w_{1i} \\cdot \\hat{\\alpha_1} \\cdot n_1 \\dots w_{Ni} \\cdot \\hat{\\alpha_N} \\cdot n_N}{w_{1i} \\cdot n_1 \\dots w_{Ni} \\cdot n_N} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss for cluster $c_i$\n",
    "\n",
    "\n",
    "$\\mathcal{L}_{c_i} = \\frac{1}{2}(\\tilde{\\alpha_i} - \\hat{\\alpha_{c_i}})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def gradientMethod(ds):\n",
    "        alphaHat : init alphaHat for each bag\n",
    "        alpha_C : get K global alpha estimates\n",
    "        init W randomly\n",
    "        for each iteration:\n",
    "            # calcualte loss given the current values of alphaHat and w\n",
    "            loss = lossFunction(w[:,1], alpha_C[1]) + ... + lossFunction(w[:,K], alpha_C[K])\n",
    "            # update alphaHat\n",
    "            alphaHat = alphaHat - eta * grad(loss)\n",
    "            # calculate the loss give the current w and new alphaHats\n",
    "            loss = lossFunction(1) + ... + lossFunction(K)\n",
    "            w = w - eta * grad(loss)\n",
    "            getMAE(alphaHat, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from multiinstance.dataset_utils import buildDataset\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.distanceApproaches import *\n",
    "from multiinstance.agglomerative_clustering import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def getAlphaLoss(w,n, alphaHats):\n",
    "    def loss(alpha):\n",
    "        lossVal = 0\n",
    "        for wi, aH in zip(w, alphaHats):\n",
    "            tilde = (1 / np.dot(wi,n)) * np.dot(np.multiply(alpha,wi),n)\n",
    "            lossVal += .5 * np.square(aH - tilde)\n",
    "        return lossVal\n",
    "    return loss\n",
    "    \n",
    "def getWLoss(a,n, alphaHats):\n",
    "    def loss(w):\n",
    "        lossVal = 0\n",
    "        for wi,aH in zip(w, alphaHats):\n",
    "            tilde = (1 / np.dot(wi,n)) * np.dot(np.multiply(a,wi),n)\n",
    "            lossVal += .5 * np.square(aH - tilde)\n",
    "        return lossVal\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def getAlphaHat(dsi,reps=10):\n",
    "    P, U = list(zip(*[dsi.getBag(int(i)) for i in range(dsi.N)]))\n",
    "    p = np.concatenate(P)\n",
    "    u = np.concatenate(U)\n",
    "    alphaHats,_ = getEsts(p,u,reps)\n",
    "    return alphaHats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initDS():\n",
    "    dsi = buildDataset(100,alphaDistr=lambda: np.random.uniform(0.1,.5))\n",
    "\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)\n",
    "    return dsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def gradientMethod(dsi):\n",
    "    alphaHats = getAlphaHat(dsi,50)\n",
    "    # initialize values for gradient method\n",
    "    a = dsi.alphaHats.mean(1)\n",
    "    n = dsi.numU\n",
    "    w = np.random.uniform(low=0.01,high=1,size=(len(alphaHats),\n",
    "                                                n.shape[0]))\n",
    "    maes = [np.mean(np.abs(a - dsi.trueAlphas.flatten()))]\n",
    "    epochs = 100\n",
    "    # Run gradient method\n",
    "    for i in tqdm(range(epochs),total=epochs):\n",
    "        alphaLossFn = getAlphaLoss(w,n,alphaHats)\n",
    "        alphaGrad = grad(alphaLossFn)\n",
    "        a = a - .025 * alphaGrad(a)\n",
    "        wLossFn = getWLoss(a,n,alphaHats)\n",
    "        wGrad = grad(wLossFn)\n",
    "        w = w - .025 * wGrad(w)\n",
    "        maes.append(np.mean(np.abs(a - dsi.trueAlphas.flatten())))\n",
    "    return maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in tqdm(range(10),total=10,desc=\"reps\"):\n",
    "    # build dataset\n",
    "    dsi = initDS()\n",
    "    # Run gradient method\n",
    "    maes = gradientMethod(dsi)\n",
    "    # Run agglomerative clustering\n",
    "    agg0 = AgglomerativeClustering(dsi, .5,use_alphas_as_scores=False)\n",
    "    agg0.cluster()\n",
    "    # plot results\n",
    "    fig,ax = plt.subplots(1,4,figsize=(16,4))\n",
    "    ax[0].plot(maes,label=\"gradient\")\n",
    "    ax[0].plot(agg0.meanAbsErrs,label=\"agg\")\n",
    "    ax[0].legend()\n",
    "    ax[1].hist(dsi.trueAlphas)\n",
    "    ax[1].set_title(r\"$\\alpha$\")\n",
    "    ax[2].hist(dsi.numP)\n",
    "    ax[2].set_title(\"Num Positive\")\n",
    "    ax[3].hist(dsi.numU)\n",
    "    ax[3].set_title(\"Num Unlabeled\")\n",
    "    plt.savefig(\"figs/nb_09/fig_{}.pdf\".format(rep),format=\"pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad,hessian, jit, vmap, partial\n",
    "\n",
    "from multiinstance.data.realData import buildDataset as buildReal\n",
    "from glob import glob\n",
    "\n",
    "from jax.test_util import check_grads\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "\n",
    "from multiinstance.ward_clustering import WardClustering\n",
    "\n",
    "from multiinstance.utils import *\n",
    "\n",
    "import scipy.stats as ss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from multiinstance.data.realData import buildDataset as buildReal\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLikelihood(alphas, mu, sigma):\n",
    "    ll = jnp.sum(jax.scipy.stats.norm.logpdf(alphas,mu,sigma))\n",
    "    return ll / len(alphas)\n",
    "\n",
    "\n",
    "def getLevelClusters(rowNum, clusterAssignments):\n",
    "    clusterLabels = jnp.unique(clusterAssignments[rowNum])\n",
    "    clusters = {c : jnp.where(clusterAssignments[rowNum] == c)[0] for c in clusterLabels}\n",
    "    return clusters\n",
    "\n",
    "def getClusterMean(leafMeans, numU, clusterMembers):\n",
    "    n = numU[clusterMembers]\n",
    "    a = leafMeans[clusterMembers]\n",
    "    return jnp.dot(a,n) * (1 / jnp.sum(n))\n",
    "    \n",
    "def treeNegLogLikelihood(leafMeans, clusterVars, alphaHatMat, numU, clusterAssigments, loc2Idx):\n",
    "    NLL = 0\n",
    "    for rowNum in range(clusterAssigments.shape[0]):\n",
    "        clusters = getLevelClusters(rowNum, clusterAssigments)\n",
    "        for clusterIdx, clusterMembers in clusters.items():\n",
    "            clusterMean = getClusterMean(leafMeans, numU, clusterMembers)\n",
    "            varIdx = loc2Idx[(rowNum, clusterIdx)]\n",
    "            clusterVar = clusterVars[varIdx]\n",
    "            alphaHats = alphaHatMat[rowNum, clusterIdx]\n",
    "            NLL = NLL - logLikelihood(alphaHats, clusterMean, clusterVar)\n",
    "    return NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(alphaHatMat, clusterAssignments):\n",
    "    leafMeans = jnp.mean(alphaHatMat[0],axis=1)\n",
    "    clusterVars = []\n",
    "    loc2Idx = {}\n",
    "    for rowNum in range(clusterAssignments.shape[0]):\n",
    "        levelClusters = jnp.unique(clusterAssignments[rowNum])\n",
    "        for cluster in levelClusters:\n",
    "            loc2Idx[(rowNum,cluster)] = len(clusterVars)\n",
    "            alphaHats = alphaHatMat[rowNum, cluster]\n",
    "            _,v = ss.norm.fit(alphaHats)\n",
    "            clusterVars.append(v)\n",
    "    clusterVars = jnp.array(clusterVars)\n",
    "    return leafMeans, clusterVars, loc2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(ds, clusterAssignments, alphaHatMat, NIterations=100, lr=0.01):\n",
    "    \n",
    "    leafMeans, clusterVars, loc2Idx = prep(alphaHatMat, clusterAssignments)\n",
    "#     meanHistory = [leafMeans]\n",
    "#     scaleHistory = [clusterVars]\n",
    "#     maes = [jnp.mean(jnp.abs(ds.trueAlphas.flatten() - leafMeans))]\n",
    "    numU = jnp.array(ds.numU)\n",
    "    # Define gradient and hessian\n",
    "    meanVarGrad = grad(treeNegLogLikelihood,argnums=(0,1))\n",
    "    meanHessian = jax.jacfwd(jax.jacrev(lambda m,v: treeNegLogLikelihood(m, v, alphaHatMat, numU, clusterAssignments, loc2Idx)))\n",
    "    varHessian = jax.jacfwd(jax.jacrev(lambda v,m: treeNegLogLikelihood(m, v, alphaHatMat, numU, clusterAssignments, loc2Idx)))\n",
    "    # Run Iterations\n",
    "    for iteration in tqdm(range(NIterations),total=NIterations,leave=False):\n",
    "        meanGrad, varGrad = meanVarGrad(leafMeans, clusterVars, alphaHatMat, numU, clusterAssignments, loc2Idx)\n",
    "        leafMeans = leafMeans - lr * jnp.linalg.inv(meanHessian(leafMeans, clusterVars)) @ meanGrad\n",
    "        clusterVars = clusterVars - lr * jnp.linalg.inv(varHessian(clusterVars, leafMeans)) @ varGrad\n",
    "#         meanHistory.append(leafMeans)\n",
    "#         scaleHistory.append(clusterVars)\n",
    "#         maes.append(jnp.mean(jnp.abs(ds.trueAlphas.flatten() - leafMeans)))\n",
    "#     return leafMeans, clusterVars, loc2Idx, meanHistory, scaleHistory, maes\n",
    "    return leafMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def posteriorCorrection(tau, alpha, S0S1):\n",
    "    post =  alpha * S0S1 * (tau / (1 - tau))\n",
    "    post[np.isinf(post)] = 1\n",
    "    return post\n",
    "\n",
    "def correctedAUC(ds,bagAlphaHats,):\n",
    "    _, tauArrays = list(zip(*[getTransformScores(ds,i) for i in range(ds.N)]))\n",
    "    S0_S1 = ds.numU/ds.numP\n",
    "    posteriors = [posteriorCorrection(tau,alphaHat, s0s1) for tau,alphaHat,s0s1 in zip(tauArrays,\n",
    "                                                                                       bagAlphaHats,\n",
    "                                                                                       S0_S1)]\n",
    "    posteriorVals = np.concatenate(posteriors)\n",
    "    hiddenLabels = np.concatenate([ds.hiddenLabels[i][:ds.numU[i]] for i in range(ds.N)])\n",
    "    return roc_auc_score(hiddenLabels, posteriorVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absErrs = {\"local\":[],\n",
    "           \"forest\":[],\n",
    "           \"global\": []}\n",
    "\n",
    "aucVals = {\"local\":[],\n",
    "           \"forest\":[],\n",
    "           \"global\": []}\n",
    "N = 0\n",
    "NIters = 5\n",
    "for f in tqdm(glob(\"/ssdata/ClassPriorEstimationPrivate/data/rawDatasets/*.mat\")):\n",
    "# for f in tqdm(glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")):\n",
    "    dsi = buildReal(f,16,\n",
    "                    alphaDistr=lambda: np.random.uniform(.05,.95),\n",
    "                    nPDistr=lambda: 1 + np.random.poisson(10),\n",
    "                    nUDistr=lambda: 1 + np.random.poisson(25))\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi,reps=10)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,\n",
    "                                               numbootstraps=100)\n",
    "    globalAE = np.abs(dsi.trueAlphas.flatten() - dsi.globalAlphaHats.mean())\n",
    "    localAE = np.abs(dsi.trueAlphas.flatten() - dsi.alphaHats.mean(1))\n",
    "    absErrs[\"global\"].append(globalAE.sum())\n",
    "    absErrs[\"local\"].append(localAE.sum())\n",
    "    aucVals[\"local\"].append(correctedAUC(dsi,dsi.alphaHats.mean(1)))\n",
    "    aucVals[\"global\"].append(correctedAUC(dsi,np.ones(dsi.N)*dsi.globalAlphaHats.mean()))\n",
    "    # Random Clustering\n",
    "    means = np.zeros((NIters,dsi.N))\n",
    "    for iteration in range(NIters):\n",
    "        wrd = WardClustering(dsi,\n",
    "                             numbootstraps=dsi.alphaHats.shape[1],\n",
    "                             randomPairing=True)\n",
    "        wrd.cluster()\n",
    "        leafMeans = run(dsi,\n",
    "                        wrd.clusterAssignment.astype(int),\n",
    "                        wrd.alphaHatMat,\n",
    "                        lr=0.01, NIterations=200)\n",
    "        means[iteration] = leafMeans\n",
    "    ests = means.mean(0)\n",
    "    absErrs[\"forest\"].append(np.abs(dsi.trueAlphas.flatten() - ests).sum())\n",
    "    aucVals[\"forest\"].append(correctedAUC(dsi, ests))\n",
    "    N += dsi.N\n",
    "    print(\"MAE\")\n",
    "    print(\"local: {:.3f}\".format(np.sum(absErrs[\"local\"])/N))\n",
    "    print(\"forest: {:.3f}\".format(np.sum(absErrs[\"forest\"])/N))\n",
    "    print(\"global: {:.3f}\".format(np.sum(absErrs[\"global\"])/N))\n",
    "    print(\"AUC\")\n",
    "    print(\"local: {:.3f}\".format(np.mean(aucVals[\"local\"])))\n",
    "    print(\"forest: {:.3f}\".format(np.mean(aucVals[\"forest\"])))\n",
    "    print(\"global: {:.3f}\".format(np.mean(aucVals[\"global\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

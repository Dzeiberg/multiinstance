{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad,hessian, jit, vmap\n",
    "\n",
    "from multiinstance.data.realData import buildDataset as buildReal\n",
    "from glob import glob\n",
    "\n",
    "from jax.test_util import check_grads\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "\n",
    "from multiinstance.ward_clustering import WardClustering\n",
    "\n",
    "from multiinstance.utils import *\n",
    "\n",
    "import scipy.stats as ss\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLikelihood(alphas, mu, sigma):\n",
    "    ll = jnp.sum(jax.scipy.stats.norm.logpdf(alphas,mu,sigma))\n",
    "    return ll / len(alphas)\n",
    "\n",
    "def getLevelClusters(rowNum, clusterAssignments):\n",
    "    clusterLabels = jnp.unique(clusterAssignments[rowNum])\n",
    "    clusters = {c : jnp.where(clusterAssignments[rowNum] == c)[0] for c in clusterLabels}\n",
    "    return clusters\n",
    "\n",
    "def getClusterMean(leafMeans, numU, clusterMembers):\n",
    "    n = numU[clusterMembers]\n",
    "    a = leafMeans[clusterMembers]\n",
    "    return jnp.dot(a,n) * (1 / jnp.sum(n))\n",
    "    \n",
    "def treeNegLogLikelihood(leafMeans, clusterVars, alphaHatMat, numU, clusterAssigments, loc2Idx):\n",
    "    NLL = 0\n",
    "    for rowNum in range(clusterAssigments.shape[0]):\n",
    "        clusters = getLevelClusters(rowNum, clusterAssigments)\n",
    "        for clusterIdx, clusterMembers in clusters.items():\n",
    "            clusterMean = getClusterMean(leafMeans, numU, clusterMembers)\n",
    "            varIdx = loc2Idx[(rowNum, clusterIdx)]\n",
    "            clusterVar = clusterVars[varIdx]\n",
    "            alphaHats = alphaHatMat[rowNum, clusterIdx]\n",
    "            NLL = NLL - logLikelihood(alphaHats, clusterMean, clusterVar)\n",
    "    return NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(alphaHatMat, clusterAssignments):\n",
    "    leafMeans = jnp.mean(alphaHatMat[0],axis=1)\n",
    "    clusterVars = []\n",
    "    loc2Idx = {}\n",
    "    for rowNum in range(clusterAssignments.shape[0]):\n",
    "        levelClusters = jnp.unique(clusterAssignments[rowNum])\n",
    "        for cluster in levelClusters:\n",
    "            loc2Idx[(rowNum,cluster)] = len(clusterVars)\n",
    "            alphaHats = alphaHatMat[rowNum, cluster]\n",
    "            _,v = ss.norm.fit(alphaHats)\n",
    "            clusterVars.append(v)\n",
    "    clusterVars = jnp.array(clusterVars)\n",
    "    return leafMeans, clusterVars, loc2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(ds, clusterAssignments, alphaHatMat, NIterations=100, lr=0.01):\n",
    "    \n",
    "    leafMeans, clusterVars, loc2Idx = prep(alphaHatMat, clusterAssignments)\n",
    "    meanHistory = [leafMeans]\n",
    "    scaleHistory = [clusterVars]\n",
    "    maes = [jnp.mean(jnp.abs(ds.trueAlphas.flatten() - leafMeans))]\n",
    "    numU = jnp.array(ds.numU)\n",
    "    # Define gradient and hessian\n",
    "#     check_grads(treeNegLogLikelihood, (leafMeans, clusterVars, \n",
    "#                                        alphaHatMat, numU,\n",
    "#                                        clusterAssignments, loc2Idx),order=1)\n",
    "    meanVarGrad = grad(treeNegLogLikelihood,argnums=(0,1))\n",
    "    meanHessian = jax.jacfwd(jax.jacrev(lambda m,v: treeNegLogLikelihood(m, v, alphaHatMat, numU, clusterAssignments, loc2Idx)))\n",
    "    varHessian = jax.jacfwd(jax.jacrev(lambda v,m: treeNegLogLikelihood(m, v, alphaHatMat, numU, clusterAssignments, loc2Idx)))\n",
    "    meanVarHessian = grad(grad(treeNegLogLikelihood,argnums=(0,1)), argnums=(0,1))\n",
    "    # Run Iterations\n",
    "    for iteration in tqdm(range(NIterations),total=NIterations):\n",
    "        meanGrad, varGrad = meanVarGrad(leafMeans, clusterVars, alphaHatMat, numU, clusterAssignments, loc2Idx)\n",
    "        leafMeans = leafMeans - lr * jnp.linalg.inv(meanHessian(leafMeans, clusterVars)) @ meanGrad\n",
    "        clusterVars = clusterVars - lr * jnp.linalg.inv(varHessian(clusterVars, leafMeans)) @ varGrad\n",
    "        #leafMeans = leafMeans - lr * meanGrad\n",
    "        #clusterVars = clusterVars - lr * varGrad\n",
    "        meanHistory.append(leafMeans)\n",
    "        scaleHistory.append(clusterVars)\n",
    "        maes.append(jnp.mean(jnp.abs(ds.trueAlphas.flatten() - leafMeans)))\n",
    "    return leafMeans, clusterVars, loc2Idx, meanHistory, scaleHistory, maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistrTree(trueAlphas, alphaHatMat, meanHistory, scaleHistory,loc2Index,clusterAssignments, numU):\n",
    "    rows,cols = list(zip(*list(loc2Idx.keys())))\n",
    "    Nrows = np.max(rows) + 1\n",
    "    Ncols = np.max(cols) + 1\n",
    "    fig,ax = plt.subplots(nrows=Nrows,ncols=Ncols, figsize=(5 * Nrows, 5*Ncols))\n",
    "    for row in range(clusterAssignments.shape[0]):\n",
    "        clusters = np.unique(clusterAssignments[row])\n",
    "        for c in clusters:\n",
    "            scale = scaleHistory[-1][loc2Index[(row,c)]]\n",
    "            scale0 = scaleHistory[0][loc2Index[(row,c)]]\n",
    "            children = np.where(clusterAssignments[row] == c)[0]\n",
    "            childMeans = meanHistory[-1][children]\n",
    "            childMeans0 = meanHistory[0][children]\n",
    "            childN = numU[children]\n",
    "            mu = np.dot(childMeans, childN) / childN.sum()\n",
    "            mu0 = np.dot(childMeans0, childN) / childN.sum()\n",
    "            alpha = np.dot(trueAlphas[children], childN)/ childN.sum()\n",
    "            ax[row,c].plot(np.arange(0,1,.01),\n",
    "                           ss.norm.pdf(np.arange(0,1,.01),loc=mu,scale=scale),color=\"green\")\n",
    "            ax[row,c].plot(np.arange(0,1,.01),\n",
    "                           ss.norm.pdf(np.arange(0,1,.01),loc=mu0,scale=scale0),color=\"red\",alpha=.5)\n",
    "            ax[row,c].hist(alphaHatMat[row,c],density=True,color=\"blue\")\n",
    "            ax[row,c].vlines(alpha, 0,1,color=\"red\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = buildDataset(1,alphaDistr=lambda: np.random.choice([.2]),\n",
    "                  nP=100,nU=200,posMean=5,negMean=1,cov=1)\n",
    "ds2 = buildDataset(1,alphaDistr=lambda: np.random.choice([.8]),\n",
    "                  nP=100,nU=200,posMean=5,negMean=1,cov=1)\n",
    "ds.merge(ds2)\n",
    "ds = addTransformScores(ds)\n",
    "ds.alphaHats,ds.curves = getBagAlphaHats(ds,numbootstraps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward = WardClustering(ds,numbootstraps=ds.alphaHats.shape[1],randomPairing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafMeans, clusterVars, loc2Idx,meanHistory, scaleHistory,maes = run(ds,ward.clusterAssignment.astype(int),\n",
    "                                                                     ward.alphaHatMat,lr=0.01,NIterations=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotDistrTree(ds.trueAlphas.flatten(),\n",
    "              ward.alphaHatMat, meanHistory,\n",
    "              scaleHistory, loc2Idx,\n",
    "              ward.clusterAssignment.astype(int), ds.numU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiinstance.data.realData import buildDataset as buildReal\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def posteriorCorrection(tau, alpha, S0S1):\n",
    "    post =  alpha * S0S1 * (tau / (1 - tau))\n",
    "    post[np.isinf(post)] = 1\n",
    "    return post\n",
    "\n",
    "def correctedAUC(ds,bagAlphaHats,):\n",
    "    _, tauArrays = list(zip(*[getTransformScores(ds,i) for i in range(ds.N)]))\n",
    "    S0_S1 = ds.numU/ds.numP\n",
    "    posteriors = [posteriorCorrection(tau,alphaHat, s0s1) for tau,alphaHat,s0s1 in zip(tauArrays,\n",
    "                                                                                       bagAlphaHats,\n",
    "                                                                                       S0_S1)]\n",
    "    posteriorVals = np.concatenate(posteriors)\n",
    "    hiddenLabels = np.concatenate([ds.hiddenLabels[i][:ds.numU[i]] for i in range(ds.N)])\n",
    "    return roc_auc_score(hiddenLabels, posteriorVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absErrs = {\"local\":[],\n",
    "           \"random\":[],\n",
    "           \"ward\":[],\n",
    "           \"global\": []}\n",
    "\n",
    "aucVals = {\"local\":[],\n",
    "           \"random\":[],\n",
    "           \"ward\":[],\n",
    "           \"global\": []}\n",
    "N = 0\n",
    "# for f in tqdm(glob(\"/ssdata/ClassPriorEstimationPrivate/data/rawDatasets/*.mat\")):\n",
    "for f in tqdm(glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")):\n",
    "    dsi = buildReal(f,32,\n",
    "                    alphaDistr=lambda: np.random.uniform(.05,.95),\n",
    "                    nPDistr=lambda: 1 + np.random.poisson(10),\n",
    "                    nUDistr=lambda: 1 + np.random.poisson(25))\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi,reps=10)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,\n",
    "                                               numbootstraps=100)\n",
    "    globalMAE = np.mean(np.abs(dsi.trueAlphas.flatten() - dsi.globalAlphaHats.mean()))\n",
    "    absErrs[\"global\"].append(globalMAE * dsi.N)\n",
    "    aucVals[\"local\"].append(correctedAUC(dsi,dsi.alphaHats.mean(1)))\n",
    "    aucVals[\"global\"].append(correctedAUC(dsi,np.ones(dsi.N)*dsi.globalAlphaHats.mean()))\n",
    "    # Random Clustering\n",
    "    wrd2 = WardClustering(dsi,numbootstraps=dsi.alphaHats.shape[1],randomPairing=True)\n",
    "    wrd2.cluster()\n",
    "    leafMeans2, clusterVars2, loc2Idx2,meanHistory2, scaleHistory2,maes2 = run(dsi,\n",
    "                                                                               wrd2.clusterAssignment.astype(int),\n",
    "                                                                               wrd2.alphaHatMat,\n",
    "                                                                               lr=0.01, NIterations=200)\n",
    "    absErrs[\"local\"].append(maes2[0] * dsi.N)\n",
    "    absErrs[\"random\"].append(maes2[-1] * dsi.N)\n",
    "    aucVals[\"random\"].append(correctedAUC(dsi, leafMeans2))\n",
    "    maefig,ax = plt.subplots()\n",
    "    ax.plot(maes2,label=\"random\")\n",
    "    ax.hlines(globalMAE,0,len(maes2),label=\"global\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    N += dsi.N\n",
    "    print(\"MAE\")\n",
    "    print(\"local: {:.3f}\".format(np.sum(absErrs[\"local\"])/N))\n",
    "    print(\"random: {:.3f}\".format(np.sum(absErrs[\"random\"])/N))\n",
    "    print(\"global: {:.3f}\".format(np.sum(absErrs[\"global\"])/N))\n",
    "    print(\"AUC\")\n",
    "    print(\"local: {:.3f}\".format(np.mean(aucVals[\"local\"])))\n",
    "    print(\"random: {:.3f}\".format(np.mean(aucVals[\"random\"])))\n",
    "    print(\"global: {:.3f}\".format(np.mean(aucVals[\"global\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE\")\n",
    "print(\"local: {:.3f}\".format(np.sum(absErrs[\"local\"])/N))\n",
    "#print(\"ward: {:.3f}\".format(np.sum(absErrs[\"ward\"])/N))\n",
    "print(\"random: {:.3f}\".format(np.sum(absErrs[\"random\"])/N))\n",
    "print(\"global: {:.3f}\".format(np.sum(absErrs[\"global\"])/N))\n",
    "print(\"AUC\")\n",
    "print(\"local: {:.3f}\".format(np.mean(aucVals[\"local\"])))\n",
    "#print(\"ward: {:.3f}\".format(np.mean(aucVals[\"ward\"])))\n",
    "print(\"random: {:.3f}\".format(np.mean(aucVals[\"random\"])))\n",
    "print(\"global: {:.3f}\".format(np.mean(aucVals[\"global\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 Datasets\n",
    "\n",
    "dsi = buildReal(f,16,\n",
    "                    alphaDistr=lambda: np.random.uniform(.05,.95),\n",
    "                    nPDistr=lambda: 1 + np.random.poisson(10),\n",
    "                    nUDistr=lambda: 1 + np.random.poisson(25))\n",
    "                    \n",
    "MAE\n",
    "* local: 0.160\n",
    "* random: 0.146\n",
    "* global: 0.230\n",
    "\n",
    "AUC\n",
    "* local: 0.847\n",
    "* random: 0.849\n",
    "* global: 0.827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26 datasets:\n",
    "\n",
    "avg P 25\n",
    "\n",
    "avg U 75\n",
    "\n",
    "MAE\n",
    "\n",
    "* local: 0.117\n",
    "* ward: 0.109\n",
    "* random: 0.103\n",
    "* global: 0.141\n",
    "\n",
    "\n",
    "AUC\n",
    "* local: 0.881\n",
    "* ward: 0.881\n",
    "* random: 0.881\n",
    "* global: 0.884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

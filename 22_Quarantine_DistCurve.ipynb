{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "from autograd import grad,jacobian,hessian\n",
    "from autograd.scipy import stats as agss\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "from glob import glob\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "from multiinstance.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sched_setaffinity(0, range(40,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def logLikelihood(xi,mu,sigma,normalize):\n",
    "    LL = (-len(xi)/2 * np.log(2*np.pi*(sigma + 1e-8)**2) - (1/(2*(sigma + 1e-8)**2)) * np.sum((xi - mu)**2))\n",
    "    if normalize:\n",
    "        LL = LL * (1/len(xi))\n",
    "    return LL\n",
    "\n",
    "def getChildren(idx,N):\n",
    "    if idx > N - 1:\n",
    "        return np.array([idx])\n",
    "    left = 2 * idx + 1\n",
    "    right = left + 1\n",
    "    \n",
    "    return np.concatenate([getChildren(left,N),getChildren(right,N)])\n",
    "\n",
    "def treeNegativeLogLikelihood(x,leafN,normalize=True,rlambda=.5):\n",
    "    def LL(leafMeans,bagSigma):\n",
    "        NBags = len(bagSigma)\n",
    "        NInternal_Nodes = np.floor(NBags/2)\n",
    "        NLeaves = len(leafMeans)\n",
    "        ll = 0\n",
    "        Nrows = int(np.ceil(np.log2(NLeaves))) + 1\n",
    "        for row in range(Nrows):\n",
    "            for col in range(2**row):\n",
    "                idx = col\n",
    "                if row > 0:\n",
    "                    idx += 2**(row) - 1                \n",
    "                leafIndices = (getChildren(idx, NInternal_Nodes) - NInternal_Nodes).astype(int)\n",
    "                ln = leafN[leafIndices]\n",
    "                mu = np.dot(leafMeans[leafIndices],ln)/np.sum(ln)\n",
    "                sigma = bagSigma[idx]\n",
    "                ll = ll + (rlambda**row) * logLikelihood(x[idx],mu,sigma,normalize)\n",
    "        return -1 * ll\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepDS(dsi,numbootstraps=100,internalScale=.1, leafScale=.25, leafBias=0):\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi)\n",
    "#     dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=numbootstraps)\n",
    "\n",
    "    dsi.numLeaves = dsi.N\n",
    "    dsi.numNodes = dsi.numLeaves + (dsi.numLeaves - 1)\n",
    "    dsi.numInternal = dsi.numNodes - dsi.numLeaves\n",
    "\n",
    "    dsi.mu = np.zeros(dsi.N)\n",
    "    dsi.sigma = np.ones(dsi.numNodes)\n",
    "    dsi.leafN = np.ones_like(dsi.mu) * numbootstraps\n",
    "    dsi.treeAlphaHats = [[] for _ in range(dsi.numNodes)]\n",
    "\n",
    "    for nodeNum in range(dsi.numInternal):\n",
    "        children = getChildren(nodeNum, dsi.numInternal)\n",
    "        leafNums = children - dsi.numInternal\n",
    "        _,unlabeled = list(zip(*[getTransformScores(dsi,n) for n in leafNums]))\n",
    "        pos,_ = list(zip(*[getTransformScores(dsi,n) for n in range(dsi.N)]))\n",
    "        pos = np.concatenate(pos).reshape((-1,1))\n",
    "        unlabeled = np.concatenate(unlabeled).reshape((-1,1))\n",
    "        NEstimates = int(np.sum([dsi.leafN[l] for l in leafNums]))\n",
    "        #dsi.treeAlphaHats[nodeNum],_ = getEsts(pos, unlabeled, NEstimates)\n",
    "        leafIndices = getChildren(nodeNum, dsi.N - 1).astype(int) - (dsi.N-1)\n",
    "        ln = dsi.numU[leafIndices]\n",
    "        alphaTilde = np.dot(dsi.trueAlphas[leafIndices].flatten(),ln)/np.sum(ln)\n",
    "        dsi.treeAlphaHats[nodeNum] = alphaTilde + np.random.normal(scale=internalScale,\n",
    "                                                                    size=NEstimates)\n",
    "        _, dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "\n",
    "    for leafNum in range(dsi.numLeaves):\n",
    "        nodeNum = leafNum + dsi.numInternal\n",
    "#         dsi.treeAlphaHats[nodeNum] = dsi.alphaHats[leafNum]\n",
    "        dsi.treeAlphaHats[nodeNum] = dsi.trueAlphas[leafNum] + leafBias + np.random.normal(scale=leafScale,\n",
    "                                                                               size=numbootstraps)\n",
    "        dsi.mu[leafNum],dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "    return dsi\n",
    "\n",
    "def runAlgorithm(dsi,normalize=True,NIter=1000,rlambda=.5):\n",
    "\n",
    "    maes = [np.mean(np.abs(dsi.mu - dsi.trueAlphas.flatten()))]\n",
    "    lr = .01\n",
    "\n",
    "    gradNLL_mu = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,\n",
    "                                                dsi.leafN,\n",
    "                                                normalize=normalize,\n",
    "                                                rlambda=rlambda),0)\n",
    "    gradNLL_sigma = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,\n",
    "                                                   dsi.leafN,\n",
    "                                                   normalize=normalize,\n",
    "                                                   rlambda=rlambda),1)\n",
    "    mus = [dsi.mu]\n",
    "    negLogLikelihood = []\n",
    "    nllfunc = treeNegativeLogLikelihood(dsi.treeAlphaHats, dsi.leafN)\n",
    "    sigmas = [dsi.sigma]\n",
    "    for i in tqdm(range(NIter),total=NIter):\n",
    "        if not i % 1500:\n",
    "            lr = lr * .5\n",
    "        deltaMu = gradNLL_mu(dsi.mu,dsi.sigma)\n",
    "        deltaSigma = gradNLL_sigma(dsi.mu,dsi.sigma)\n",
    "        mus.append(dsi.mu)\n",
    "        sigmas.append(dsi.sigma)\n",
    "        dsi.mu = dsi.mu - lr * deltaMu\n",
    "        dsi.mu[dsi.mu <= 0] = .01\n",
    "        negLogLikelihood.append(nllfunc(dsi.mu, dsi.sigma))\n",
    "        dsi.sigma = dsi.sigma - lr * deltaSigma\n",
    "        maes.append(np.mean(np.abs(dsi.mu - dsi.trueAlphas.flatten())))\n",
    "    return dsi,mus,sigmas,maes,logLikelihood\n",
    "\n",
    "def plotMAE(maes,dsi):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(maes,label=\"likelihood method\")\n",
    "    ax.hlines(np.mean(np.abs(dsi.globalAlphaHats.mean() - dsi.trueAlphas.flatten())),\n",
    "               0,len(maes),\n",
    "               color=\"black\",label=\"global\")\n",
    "    ax.legend()\n",
    "    return fig\n",
    "\n",
    "def plotDistrs(ds,mus_,sigmas_):\n",
    "    Nrows = int(np.ceil(np.log2(ds.N))) + 1\n",
    "    fig,ax= plt.subplots(nrows=Nrows,ncols=ds.N,figsize=(5 * ds.N,5 * ds.N))\n",
    "    for row in range(Nrows):\n",
    "        for col in range(2**row):\n",
    "            idx = col\n",
    "            if row > 0:\n",
    "                idx += 2**(row) - 1\n",
    "            ax[row,col].hist(ds.treeAlphaHats[idx],density=True)\n",
    "            leafIndices = getChildren(idx, ds.N - 1).astype(int) - (ds.N-1)\n",
    "            ln = ds.numU[leafIndices]\n",
    "            # Final\n",
    "            mu = np.dot(ds.mu[leafIndices],ln)/np.sum(ln)\n",
    "            sigma = ds.sigma[idx]\n",
    "            pdf = ss.norm.pdf(np.arange(0,\n",
    "                                        ds.treeAlphaHats[idx].max(),\n",
    "                                        .01),\n",
    "                              loc=mu,scale=sigma)\n",
    "            ax[row,col].plot(np.arange(0,\n",
    "                                       ds.treeAlphaHats[idx].max(),\n",
    "                                       .01),\n",
    "                             pdf,color=\"green\",alpha=.5,label=\"final\")\n",
    "            ax[row,col].vlines(mu,0,1,color=\"green\",label=\"alpha hat\")\n",
    "            # Original\n",
    "            mu = np.dot(mus_[0][leafIndices],ln)/np.sum(ln)\n",
    "            sigma = sigmas_[0][idx]\n",
    "            pdf = ss.norm.pdf(np.arange(0,ds.treeAlphaHats[idx].max(),.01),\n",
    "                              loc=mu,scale=sigma)\n",
    "            ax[row,col].plot(np.arange(0,ds.treeAlphaHats[idx].max(),.01),pdf,color=\"red\",alpha=.5,label=\"og\")\n",
    "            truth = np.dot(ds.trueAlphas[leafIndices].flatten(), ln)/np.sum(ln)\n",
    "            ax[row,col].vlines(truth,0,1,color=\"black\",label=\"alpha\")\n",
    "            if row == Nrows - 1:\n",
    "                ax[row,col].vlines(ds.trueAlphas[leafIndices[0]],0,1,color=\"black\",label=\"alpha\")\n",
    "            ax[row,col].legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low variance causes problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.20]))\n",
    "ds2 = buildDataset(1, nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.60]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi,numbootstraps=1000,internalScale=0.01,leafScale=0.01,leafBias=0.00)\n",
    "dsi, mus,sigmas,maes,logLikelihood = runAlgorithm(dsi,\n",
    "                                                  NIter=500,\n",
    "                                                  rlambda=1)\n",
    "maefig1 = plotMAE(maes,dsi)\n",
    "fig1 = plotDistrs(dsi,mus,sigmas)\n",
    "print(dsi.mu, dsi.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise to estimates fixes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.20]))\n",
    "ds2 = buildDataset(1, nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.60]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi,numbootstraps=1000,internalScale=0.1,leafScale=0.1,leafBias=0.00)\n",
    "dsi, mus,sigmas,maes,logLikelihood = runAlgorithm(dsi,\n",
    "                                                  NIter=500,\n",
    "                                                  rlambda=1)\n",
    "maefig1 = plotMAE(maes,dsi)\n",
    "fig1 = plotDistrs(dsi,mus,sigmas)\n",
    "print(dsi.mu, dsi.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad leaf estimates: Equal Weight to internal and leaf nodes leads to bad result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.20]))\n",
    "ds2 = buildDataset(1, nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.60]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi,numbootstraps=1000,internalScale=0.1,leafScale=0.1,leafBias=0.20)\n",
    "dsi, mus,sigmas,maes,logLikelihood = runAlgorithm(dsi,\n",
    "                                                  NIter=500,\n",
    "                                                  rlambda=1)\n",
    "maefig1 = plotMAE(maes,dsi)\n",
    "fig1 = plotDistrs(dsi,mus,sigmas)\n",
    "print(dsi.mu, dsi.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(1,nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.20]))\n",
    "ds2 = buildDataset(1, nP=10,nU=20,posMean=6,negMean=2,cov=1,\n",
    "                   alphaDistr=lambda: np.random.choice([.60]))\n",
    "dsi.merge(ds2)\n",
    "\n",
    "dsi = prepDS(dsi,numbootstraps=1000,internalScale=0.1,leafScale=0.1,leafBias=0.20)\n",
    "dsi, mus,sigmas,maes,logLikelihood = runAlgorithm(dsi,\n",
    "                                                  NIter=500,\n",
    "                                                  rlambda=.15)\n",
    "maefig1 = plotMAE(maes,dsi)\n",
    "fig1 = plotDistrs(dsi,mus,sigmas)\n",
    "print(dsi.mu, dsi.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

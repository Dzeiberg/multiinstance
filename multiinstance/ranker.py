# AUTOGENERATED! DO NOT EDIT! File to edit: 45_Rank.ipynb (unless otherwise specified).

__all__ = ['RankNet', 'RankNet2']

# Cell
from .data.gaussian_dg import GaussianMixtureDataGenerator

import matplotlib.pyplot as plt

from dist_curve.transforms import getOptimalTransform

from sklearn.metrics import roc_auc_score

from tqdm.notebook import tqdm,trange

import numpy as np

from sklearn.model_selection import train_test_split

import tensorflow as tf

# from multiinstance.density_ratio_em import DensityRatioEM

from .nnpu import getPosterior

from easydict import EasyDict
from sklearn.model_selection import StratifiedKFold

# Cell
class RankNet:
    def buildModel(self,input_shape):
        layers = tf.keras.models.Sequential([
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(1)
        ],name="dense_layers")
        inp1 = tf.keras.layers.Input(shape=(input_shape,),name="input_1")
        inp2 = tf.keras.layers.Input(shape=(input_shape,),name="input_2")
        score_1 = layers(inp1)
        score_2 = layers(inp2)
        score_diff = tf.keras.layers.Subtract()([score_1, score_2])
        prob = tf.keras.layers.Activation("sigmoid")(score_diff)
        self.model = tf.keras.models.Model(inputs=[inp1,inp2],outputs=prob)
        self.ranker = tf.keras.backend.function([inp1],[score_1])
        self.model.compile(tf.keras.optimizers.Adam(learning_rate=1e-4),
                           loss=tf.keras.losses.BinaryCrossentropy())

    def train(self,xPU,yPU,NIters=1000, batch_size=128,):
        skf = StratifiedKFold()
        ranks = np.zeros(xPU.shape[0])
        for trainIndices,valIndices in skf.split(xPU,yPU):
            xPUTrain,xPUVal,yPUTrain,yPUVal = xPU[trainIndices],xPU[valIndices],yPU[trainIndices],yPU[valIndices]
            ranks[valIndices] = self.trainFold(xPUTrain,xPUVal,yPUTrain,yPUVal,NIters,batch_size)
        print(roc_auc_score(yPU,ranks))
        return ranks

    def trainFold(self,xPUTrain,xPUVal,yPUTrain,yPUVal,NIters=10000, batch_size=128,):
        batchesPerEpoch = np.ceil(xPUTrain.shape[0] / batch_size).astype(int) # +/- rounding error
        self.buildModel(xPUTrain.shape[1])
        # Early stopping variables
        minvalLoss,patience = np.inf,0
        posTrain,unlabeledTrain = xPUTrain[yPUTrain],xPUTrain[~yPUTrain]
        posVal,unlabeledVal = xPUVal[yPUVal],xPUVal[~yPUVal]
        for iters in trange(NIters,leave=False):
            idxs1 = np.random.randint(0,high=posTrain.shape[0],size=batch_size)
            idxs2 = np.random.randint(0,high=unlabeledTrain.shape[0],size=batch_size)
            posInputs,unlabeledInputs = posTrain[idxs1],unlabeledTrain[idxs2]
            inputs = np.stack([posInputs,unlabeledInputs],axis=-1)
            b = np.random.binomial(1,.5,inputs.shape[0]).astype(bool)
            inputs[b] = inputs[b][...,[1,0]]
            inp1,inp2 = inputs[...,0], inputs[...,1]
            target = ~b
            trainLoss = self.model.train_on_batch([inp1,inp2],target)
            if not iters % batchesPerEpoch:
                i1 = np.random.choice(range(xPUVal.shape[0]),replace=False,
                                       size=int(xPUVal.shape[0] / 2))
                i2 = np.random.choice(list(set(range(xPUVal.shape[0])) - set(i1)),size=i1.shape,replace=True)
                inp1,inp2 = xPUVal[i1],xPUVal[i2]
                y1,y2 = yPUVal[i1],yPUVal[i2]
                target = y1 > y2
                valLoss = self.model.evaluate([inp1,inp2],target)
                scores = self.ranker(xPUVal)
                if valLoss < minvalLoss:
                    print("minvalLoss, ",valLoss)
                    minvalLoss = valLoss
                    patience = 0
                else:
                    patience += 1
                if patience == 15:
                    break
        return self.ranker(xPUVal)[0].ravel()


# Cell
class RankNet2:
    def buildModel(self,input_shape):

        def loss(t,diff):
            return (1-t) * (diff) - t * (diff)

        layers = tf.keras.models.Sequential([
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(128,activation="relu"),
            tf.keras.layers.Dense(1)
        ],name="dense_layers")
        inp1 = tf.keras.layers.Input(shape=(input_shape,),name="input_1")
        inp2 = tf.keras.layers.Input(shape=(input_shape,),name="input_2")
        score_1 = layers(inp1)
        score_2 = layers(inp2)
        score_diff = tf.keras.layers.Subtract()([score_1, score_2])
        prob = tf.keras.layers.Activation("sigmoid")(score_diff)
        self.model = tf.keras.models.Model(inputs=[inp1,inp2],outputs=score_diff)
        self.ranker = tf.keras.backend.function([inp1],[score_1])
        self.model.compile(tf.keras.optimizers.Adam(learning_rate=1e-4),
                           loss=loss)

    def train(self,xPU,yPU,NIters=5000, batch_size=128,):
        skf = StratifiedKFold()
        ranks = np.zeros(xPU.shape[0])
        for trainIndices,valIndices in skf.split(xPU,yPU):
            xPUTrain,xPUVal,yPUTrain,yPUVal = xPU[trainIndices],xPU[valIndices],yPU[trainIndices],yPU[valIndices]
            ranks[valIndices] = self.trainFold(xPUTrain,xPUVal,yPUTrain,yPUVal,NIters,batch_size)
        print(roc_auc_score(yPU,ranks))
        return ranks

    def trainFold(self,xPUTrain,xPUVal,yPUTrain,yPUVal,NIters=1000, batch_size=128,):
        batchesPerEpoch = np.ceil(xPUTrain.shape[0] / batch_size).astype(int) # +/- rounding error
        self.buildModel(xPUTrain.shape[1])
        # Early stopping variables
        minvalLoss,patience = np.inf,0
        posTrain,unlabeledTrain = xPUTrain[yPUTrain],xPUTrain[~yPUTrain]
        posVal,unlabeledVal = xPUVal[yPUVal],xPUVal[~yPUVal]
        for iters in trange(NIters,leave=False):
            idxs1 = np.random.randint(0,high=posTrain.shape[0],size=batch_size)
            idxs2 = np.random.randint(0,high=unlabeledTrain.shape[0],size=batch_size)
            posInputs,unlabeledInputs = posTrain[idxs1],unlabeledTrain[idxs2]
            inputs = np.stack([posInputs,unlabeledInputs],axis=-1)
            b = np.random.binomial(1,.5,inputs.shape[0]).astype(bool)
            inputs[b] = inputs[b][...,[1,0]]
            inp1,inp2 = inputs[...,0], inputs[...,1]
            target = ~b
            target = target.astype(float)
            trainLoss = self.model.train_on_batch([inp1,inp2],target)
            if not iters % batchesPerEpoch:
                i1 = np.random.choice(range(xPUVal.shape[0]),replace=False,
                                       size=int(xPUVal.shape[0] / 2))
                i2 = np.random.choice(list(set(range(xPUVal.shape[0])) - set(i1)),size=i1.shape,replace=True)
                inp1,inp2 = xPUVal[i1],xPUVal[i2]
                y1,y2 = yPUVal[i1],yPUVal[i2]
                target = (y1 > y2).astype(float)
                valLoss = self.model.evaluate([inp1,inp2],target)
                scores = self.ranker(xPUVal)
                if valLoss < minvalLoss:
                    print("minvalLoss, ",valLoss)
                    minvalLoss = valLoss
                    patience = 0
                else:
                    patience += 1
                if patience == 15:
                    break
        return self.ranker(xPUVal)[0].ravel()

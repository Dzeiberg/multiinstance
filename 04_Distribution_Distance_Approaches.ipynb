{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp distanceApproaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiinstance.utils import *\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import community as community_louvain\n",
    "import networkx as nx\n",
    "\n",
    "from multiinstance.data.syntheticData import buildDataset\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.special import logsumexp\n",
    "import scipy.stats as ss\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def addTransformScores(ds):\n",
    "    P,U = list(zip(*[ds.getBag(i) for i in range(len(ds.numP))]))\n",
    "\n",
    "    P = np.concatenate(P)\n",
    "    U = np.concatenate(U)\n",
    "\n",
    "    X = np.concatenate((P,U))\n",
    "    Y = np.concatenate((np.ones(P.shape[0]),\n",
    "                        np.zeros(U.shape[0])))\n",
    "\n",
    "    clf = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100, max_samples=X.shape[0],\n",
    "                            max_features=X.shape[1], bootstrap=True, bootstrap_features=False, oob_score=True).fit(X,Y)\n",
    "\n",
    "    probP = clf.oob_decision_function_[:,1]\n",
    "\n",
    "    roc_auc_score(Y, probP)\n",
    "\n",
    "    Pprobs, Uprobs = splitIntoBags(probP,ds.numP, ds.numU)\n",
    "    ds.Pprobs = Pprobs\n",
    "    ds.Uprobs = Uprobs\n",
    "    return ds\n",
    "\n",
    "def splitIntoBags(probs, numP, numU):\n",
    "    probsP, probsU = probs[:numP.sum()], probs[numP.sum():]\n",
    "    pUpperIndices = np.concatenate(([0],np.cumsum(numP)))\n",
    "    uUpperIndices = np.concatenate(([0],np.cumsum(numU)))\n",
    "    P = np.zeros((len(numP), numP.max()))\n",
    "    U = np.zeros((len(numU), numU.max()))\n",
    "    for b in range(len(numP)):\n",
    "        P[b,:numP[b]] = probsP[pUpperIndices[b]:pUpperIndices[b+1]]\n",
    "        U[b,:numU[b]] = probsU[uUpperIndices[b] : uUpperIndices[b+1]]\n",
    "    return P,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransformScores(ds,i):\n",
    "    p = ds.Pprobs[i,:ds.numP[i]]\n",
    "    u = ds.Uprobs[i,:ds.numU[i]]\n",
    "    return p,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fitKDE(vec):\n",
    "    kde = KernelDensity(kernel=\"gaussian\").fit(vec)\n",
    "    return kde\n",
    "\n",
    "def KLD(lnDensI,lnDensJ):\n",
    "        return ss.entropy(np.exp(lnDensI), qk=np.exp(lnDensJ),base=2)\n",
    "    \n",
    "def JSD(ds, kdeI, i, j):\n",
    "    _,uI = getTransformScores(ds,i)\n",
    "    uI = uI.reshape((-1,1))\n",
    "    _,uJ = getTransformScores(ds,j)\n",
    "    uJ = uJ.reshape((-1,1))\n",
    "    kdeJ = fitKDE(uJ)\n",
    "    lnDensI0 = kdeI.score_samples(uI)\n",
    "    lnDensJ0 = kdeJ.score_samples(uI)\n",
    "    lnDensM0 = np.array([logsumexp((ldi,ldj),\n",
    "                                       b=np.array([.5,.5])) for ldi,ldj in zip(lnDensI0, lnDensJ0)])\n",
    "    lnDensI1 = kdeI.score_samples(uJ)\n",
    "    lnDensJ1 = kdeJ.score_samples(uJ)\n",
    "    lnDensM1 = np.array([logsumexp((ldi,ldj),\n",
    "                                       b=np.array([.5,.5])) for ldi,ldj in zip(lnDensI1, lnDensJ1)])\n",
    "    x = KLD(lnDensI0,lnDensM0)\n",
    "    y = KLD(lnDensJ1, lnDensM1)\n",
    "    return x + y\n",
    "\n",
    "def getJSDDistMat(ds):\n",
    "    N = ds.N\n",
    "    dist = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        _, uI = getTransformScores(ds,i)\n",
    "        kdeI = fitKDE(uI.reshape((-1,1)))\n",
    "        for j in range(i+1, N):\n",
    "            jsd = JSD(ds, kdeI, i,j)\n",
    "            dist[i,j] = jsd\n",
    "            dist[j,i] = jsd\n",
    "    return dist\n",
    "\n",
    "def getKLDMat(ds):\n",
    "    N = ds.N\n",
    "    dist = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        _, uI = getTransformScores(ds,i)\n",
    "        uI = uI.reshape((-1,1))\n",
    "        kdeI = fitKDE(uI)\n",
    "        for j in range(N):\n",
    "            _,uJ = getTransformScores(ds,j)\n",
    "            uJ = uJ.reshape((-1,1))\n",
    "            kdeJ = fitKDE(uJ)\n",
    "            lnDensI = kdeI.score_samples(uI)\n",
    "            lnDensJ = kdeJ.score_samples(uI)\n",
    "            dist[i,j] = KLD(lnDensI, lnDensJ)\n",
    "    return dist\n",
    "\n",
    "def getWassersteinMat(ds):\n",
    "    N = ds.N\n",
    "    dist = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        _, uI = getTransformScores(ds,i)\n",
    "#         uI = uI.reshape((-1,1))\n",
    "        for j in range(N):\n",
    "            _,uJ = getTransformScores(ds,j)\n",
    "#             uJ = uJ.reshape((-1,1))\n",
    "            dist[i,j] = ss.wasserstein_distance(uI,uJ)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimalAdjacency(trueAlphas):\n",
    "    N = trueAlphas.shape[0]\n",
    "    adj = np.zeros((N,N))\n",
    "    for i,a0 in enumerate(trueAlphas):\n",
    "        for j,a1 in enumerate(trueAlphas[i+1:],start=i+1):\n",
    "            adj[i,j] = np.abs(a0 - a1)\n",
    "            adj[j,i] = np.abs(a0 - a1)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeAEs = []\n",
    "localAEs = []\n",
    "baselineAEs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in tqdm(range(5),total=5,leave=False, desc=\"dataset rep\"):\n",
    "    ds = buildDataset(100)\n",
    "    ds = addTransformScores(ds)\n",
    "    # compute dist mat\n",
    "    wassMat = getWassersteinMat(ds)\n",
    "    order = np.argsort(ds.trueAlphas.flatten())\n",
    "    plt.figure()\n",
    "    sns.heatmap(wassMat[order][:,order])\n",
    "    plt.title(\"Wasserstein Matrix orderd by True Alpha\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(getOptimalAdjacency(ds.trueAlphas)[order][:,order])\n",
    "    plt.title(\"Alpha MAE ordered by true alpha\")\n",
    "    plt.show()\n",
    "    # find partition using Louvain alg\n",
    "    g = nx.from_numpy_array(1 / np.exp(wassMat))\n",
    "    partition = community_louvain.best_partition(g)\n",
    "    values = np.array(list(partition.values()))\n",
    "    plt.figure()\n",
    "    clusterorder = np.argsort(values)\n",
    "    sns.heatmap(getOptimalAdjacency(ds.trueAlphas)[clusterorder][:,clusterorder])\n",
    "    plt.title(\"Alpha MAE ordered by cluster assignment (K={})\".format(len(np.unique(values))))\n",
    "    plt.show()\n",
    "    ds.clusters = [np.where(values  == v)[0] for v in np.unique(values)]    \n",
    "    ds.alphaHats, ds.curves = getBagAlphaHats(ds,10)\n",
    "    ds.clusterAlphaHat, ds.clusterCurves = getCliqueAlphaHats(ds,ds.clusters, numbootstraps=10)\n",
    "\n",
    "    ds.alphaPrime = getAlphaPrime(ds.clusters, ds.clusterAlphaHat)\n",
    "\n",
    "    globalAlphaHat,_ = getCliqueAlphaHats(ds, [np.arange(ds.N)], numbootstraps=10)\n",
    "\n",
    "    primeAEs.append(np.abs(ds.alphaPrime - ds.trueAlphas))\n",
    "    localAEs.append(np.abs(ds.alphaHats - ds.trueAlphas))\n",
    "    baselineAEs.append(np.abs(ds.trueAlphas - globalAlphaHat.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(primeAEs), np.mean(localAEs), np.mean(baselineAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

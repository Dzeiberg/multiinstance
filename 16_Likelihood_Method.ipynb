{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp likelihoodMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import autograd\n",
    "from autograd import grad,jacobian,hessian\n",
    "from autograd.scipy import stats as agss\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativeLogLikelihood(x):\n",
    "    def nLL(theta):\n",
    "        ll = 0.0\n",
    "        for i in range(len(x)):\n",
    "            ll = ll + (1/len(x[i]))*(-len(x[i])/2 * np.log(2*np.pi*theta[i*2+1]**2) - (1/(2*theta[i*2+1]**2)) * np.sum((x[i] - theta[i*2])**2))\n",
    "        return -1 * ll\n",
    "    return nLL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muStar = np.array([3.5,4,3,3,5,1,5])\n",
    "sigmaStar = np.array([.5,1,1,2,2,2,2])\n",
    "N = [400,200,200,100,100,100,100]\n",
    "x = [np.random.normal(loc=mu,scale=sigma,size=(1,ni)) for mu,sigma,ni in zip(muStar,sigmaStar,N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = np.random.beta(a=1,b=1,size=(4,))\n",
    "theta = np.array([0.0, 1.0,\n",
    "                  0.0,1.0, 0.0,1.0,\n",
    "                  0.0,1.0, 0.0,1.0, 0.0,1.0, 0.0,1.0])\n",
    "gradTheta = grad(negativeLogLikelihood(x),)\n",
    "\n",
    "maes = []\n",
    "for i in range(5000):\n",
    "    theta = theta - 0.001 * gradTheta(theta)\n",
    "    aes = 0\n",
    "    for i in range(int(len(theta)/2)):\n",
    "        aes += np.abs(theta[2*i] - muStar[i])\n",
    "    maes.append(aes/(len(theta)/2))\n",
    "\n",
    "# jacobian_ = jacobian(negativeLogLikelihood(x))\n",
    "# hessian_ = hessian(negativeLogLikelihood(x))\n",
    "# for i in range(1000):\n",
    "#     j = jacobian_(theta)\n",
    "#     h = hessian_(theta)\n",
    "#     theta = theta + 0.001 * np.linalg.inv(h) @ j\n",
    "#     aes = np.abs(theta[0] - muStar[0]) + np.abs(theta[2] - muStar[1])\n",
    "#     maes.append(aes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta[3], theta[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta[7],theta[9], theta[11], theta[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In terms of Bag Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def normalizedlogLik(xi,mu,sigma):\n",
    "    return (1/len(xi))*(-len(xi)/2 * np.log(2*np.pi*sigma**2) - (1/(2*sigma**2)) * np.sum((xi - mu)**2))\n",
    "\n",
    "def getChildren(idx,N):\n",
    "    if idx > N - 1:\n",
    "        return np.array([idx])\n",
    "    left = 2 * idx + 1\n",
    "    right = left + 1\n",
    "    \n",
    "    return np.concatenate([getChildren(left,N),getChildren(right,N)])\n",
    "\n",
    "def treeNegativeLogLikelihood(x,leafN):\n",
    "    def LL(leafMeans,bagSigma):\n",
    "        NBags = len(bagSigma)\n",
    "        NInternal_Nodes = np.floor(NBags/2)\n",
    "#         NLeaves = NBags - NInternal_Nodes\n",
    "        ll = 0\n",
    "        for idx in range(NBags):\n",
    "            leafIndices = (getChildren(idx, NInternal_Nodes) - NInternal_Nodes).astype(int)\n",
    "            ln = leafN[leafIndices]\n",
    "            mu = np.dot(leafMeans[leafIndices],ln)/np.sum(ln)\n",
    "            sigma = bagSigma[idx]\n",
    "            ll = ll + normalizedlogLik(x[idx],mu,sigma)\n",
    "        return -1 * ll\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right now I'm assuming N = $2^j$ for some j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7\n",
    "N_Internal = int(np.floor((N)/2))\n",
    "NLeaves = int(N - N_Internal)\n",
    "bagMuStar = np.random.normal(loc=0,scale=10,size=NLeaves)\n",
    "bagN = np.random.poisson(lam=10,size=NLeaves)\n",
    "\n",
    "X = []\n",
    "for level in range(3):\n",
    "    NBagsInLevel = 2**level\n",
    "    start = 2**level - 1\n",
    "    for bagNum in range(start,start+NBagsInLevel):\n",
    "        childrenIndices = (getChildren(bagNum,N_Internal) - N_Internal).astype(int)\n",
    "        childrenMus = bagMuStar[childrenIndices]\n",
    "        childrenNs = bagN[childrenIndices]\n",
    "        loc = np.dot(childrenMus, childrenNs) / np.sum(childrenNs)\n",
    "        scale = 2**level\n",
    "        X.append(np.random.normal(loc=loc,scale=scale,size=np.sum(childrenNs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize as local estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros(bagMuStar.shape)\n",
    "sigma = np.ones(len(X))\n",
    "for leafNum in range(NLeaves):\n",
    "    idx = N_Internal + leafNum\n",
    "    xi = X[idx]\n",
    "    mu[leafNum],sigma[idx] = ss.norm.fit(xi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(mu - bagMuStar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "maes = []\n",
    "\n",
    "gradNLL_mu = grad(treeNegativeLogLikelihood(X,bagN),0)\n",
    "gradNLL_sigma = grad(treeNegativeLogLikelihood(X,bagN),1)\n",
    "NIter= 1000\n",
    "lr = 0.1\n",
    "for i in tqdm(range(NIter),total=NIter):\n",
    "    if not i % 5000:\n",
    "        lr = lr * .5\n",
    "    deltaMu = gradNLL_mu(mu,sigma)\n",
    "    deltaSigma = gradNLL_sigma(mu,sigma)\n",
    "    mu = mu - lr * deltaMu\n",
    "    sigma = sigma - lr * deltaSigma\n",
    "    maes.append(np.mean(np.abs(mu - bagMuStar)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp likelihoodMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "from autograd import grad,jacobian,hessian\n",
    "from autograd.scipy import stats as agss\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "from scipy.optimize import minimize\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sched_setaffinity(0,set(range(10,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sched_getaffinity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativeLogLikelihood(x):\n",
    "    def nLL(theta):\n",
    "        ll = 0.0\n",
    "        for i in range(len(x)):\n",
    "            ll = ll + (1/len(x[i]))*(-len(x[i])/2 * np.log(2*np.pi*theta[i*2+1]**2) - (1/(2*theta[i*2+1]**2)) * np.sum((x[i] - theta[i*2])**2))\n",
    "        return -1 * ll\n",
    "    return nLL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muStar = np.array([3.5,4,3,3,5,1,5])\n",
    "sigmaStar = np.array([.5,1,1,2,2,2,2])\n",
    "N = [400,200,200,100,100,100,100]\n",
    "x = [np.random.normal(loc=mu,scale=sigma,size=(1,ni)) for mu,sigma,ni in zip(muStar,sigmaStar,N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = np.random.beta(a=1,b=1,size=(4,))\n",
    "theta = np.array([0.0, 1.0,\n",
    "                  0.0,1.0, 0.0,1.0,\n",
    "                  0.0,1.0, 0.0,1.0, 0.0,1.0, 0.0,1.0])\n",
    "gradTheta = grad(negativeLogLikelihood(x),)\n",
    "\n",
    "maes = []\n",
    "for i in range(1500):\n",
    "    theta = theta - 0.001 * gradTheta(theta)\n",
    "    aes = 0\n",
    "    for i in range(int(len(theta)/2)):\n",
    "        aes += np.abs(theta[2*i] - muStar[i])\n",
    "    maes.append(aes/(len(theta)/2))\n",
    "\n",
    "# jacobian_ = jacobian(negativeLogLikelihood(x))\n",
    "# hessian_ = hessian(negativeLogLikelihood(x))\n",
    "# for i in range(1000):\n",
    "#     j = jacobian_(theta)\n",
    "#     h = hessian_(theta)\n",
    "#     theta = theta + 0.001 * np.linalg.inv(h) @ j\n",
    "#     aes = np.abs(theta[0] - muStar[0]) + np.abs(theta[2] - muStar[1])\n",
    "#     maes.append(aes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In terms of Bag Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLikelihood(xi,mu,sigma,normalize):\n",
    "    LL = (-len(xi)/2 * np.log(2*np.pi*(sigma + 1e-8)**2) - (1/(2*(sigma + 1e-8)**2)) * np.sum((xi - mu)**2))\n",
    "    if normalize:\n",
    "        LL = LL * (1/len(xi))\n",
    "    return LL\n",
    "\n",
    "def getChildren(idx,N):\n",
    "    if idx > N - 1:\n",
    "        return np.array([idx])\n",
    "    left = 2 * idx + 1\n",
    "    right = left + 1\n",
    "    \n",
    "    return np.concatenate([getChildren(left,N),getChildren(right,N)])\n",
    "\n",
    "def treeNegativeLogLikelihood(x,leafN,normalize=True):\n",
    "    def LL(leafMeans,bagSigma):\n",
    "        NBags = len(bagSigma)\n",
    "        NInternal_Nodes = np.floor(NBags/2)\n",
    "        ll = 0\n",
    "        for idx in range(NBags):\n",
    "            leafIndices = (getChildren(idx, NInternal_Nodes) - NInternal_Nodes).astype(int)\n",
    "            ln = leafN[leafIndices]\n",
    "            mu = np.dot(leafMeans[leafIndices],ln)/np.sum(ln)\n",
    "            sigma = bagSigma[idx]\n",
    "            ll = ll + logLikelihood(x[idx],mu,sigma,normalize)\n",
    "        return -1 * ll\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right now I'm assuming N = $2^j$ for some j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7\n",
    "N_Internal = int(np.floor((N)/2))\n",
    "NLeaves = int(N - N_Internal)\n",
    "bagMuStar = np.random.normal(loc=0,scale=10,size=NLeaves)\n",
    "bagN = np.random.poisson(lam=10,size=NLeaves)\n",
    "\n",
    "X = []\n",
    "for level in range(3):\n",
    "    NBagsInLevel = 2**level\n",
    "    start = 2**level - 1\n",
    "    for bagNum in range(start,start+NBagsInLevel):\n",
    "        childrenIndices = (getChildren(bagNum,N_Internal) - N_Internal).astype(int)\n",
    "        childrenMus = bagMuStar[childrenIndices]\n",
    "        childrenNs = bagN[childrenIndices]\n",
    "        loc = np.dot(childrenMus, childrenNs) / np.sum(childrenNs)\n",
    "        scale = 2**level\n",
    "        X.append(np.random.normal(loc=loc,scale=scale,size=np.sum(childrenNs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize as local estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros(bagMuStar.shape)\n",
    "sigma = np.ones(len(X))\n",
    "for leafNum in range(NLeaves):\n",
    "    idx = N_Internal + leafNum\n",
    "    xi = X[idx]\n",
    "    mu[leafNum],sigma[idx] = ss.norm.fit(xi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = []\n",
    "\n",
    "gradNLL_mu = grad(treeNegativeLogLikelihood(X,bagN),0)\n",
    "gradNLL_sigma = grad(treeNegativeLogLikelihood(X,bagN),1)\n",
    "NIter= 1000\n",
    "lr = 0.01\n",
    "for i in tqdm(range(NIter),total=NIter):\n",
    "    if not i % 5000:\n",
    "        lr = lr * .5\n",
    "    deltaMu = gradNLL_mu(mu,sigma)\n",
    "    deltaSigma = gradNLL_sigma(mu,sigma)\n",
    "    mu = mu - lr * deltaMu\n",
    "    sigma = sigma - lr * deltaSigma\n",
    "    maes.append(np.mean(np.abs(mu - bagMuStar)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = []\n",
    "\n",
    "gradNLL_mu = grad(treeNegativeLogLikelihood(X,bagN,normalize=False),0)\n",
    "gradNLL_sigma = grad(treeNegativeLogLikelihood(X,bagN,normalize=False),1)\n",
    "NIter= 5000\n",
    "lr = 0.01\n",
    "for i in tqdm(range(NIter),total=NIter):\n",
    "    if not i % 5000:\n",
    "        lr = lr * .5\n",
    "    deltaMu = gradNLL_mu(mu,sigma)\n",
    "    deltaSigma = gradNLL_sigma(mu,sigma)\n",
    "    mu = mu - lr * deltaMu\n",
    "    sigma = sigma - lr * deltaSigma\n",
    "    maes.append(np.mean(np.abs(mu - bagMuStar)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiinstance.data.realData import buildDataset\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.agglomerative_clustering import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absErrs = {\"local\":[],\n",
    "           \"global\":[],\n",
    "           \"likelihood\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")\n",
    "for fileName in tqdm(fileNames,total=len(fileNames)):\n",
    "    dsi = buildDataset(fileName,4,\n",
    "                       alphaDistr=lambda: np.random.uniform(.01,.95),\n",
    "                      nPDistr=lambda: 1 + np.random.poisson(100),\n",
    "                      nUDistr=lambda: 1 + np.random.poisson(5000))\n",
    "\n",
    "    dsi = addTransformScores(dsi)\n",
    "    dsi = addGlobalEsts(dsi)\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=50)\n",
    "\n",
    "    dsi.numLeaves = dsi.alphaHats.shape[0]\n",
    "    dsi.numNodes = dsi.numLeaves + (dsi.numLeaves - 1)\n",
    "    dsi.numInternal = dsi.numNodes - dsi.numLeaves\n",
    "\n",
    "    dsi.mu = np.zeros(dsi.alphaHats.shape[0])\n",
    "    dsi.sigma = np.ones(dsi.numNodes)\n",
    "    dsi.leafN = np.ones_like(dsi.mu) * dsi.alphaHats.shape[1]\n",
    "    dsi.treeAlphaHats = [[] for _ in range(dsi.numNodes)]\n",
    "\n",
    "    for nodeNum in range(dsi.numInternal):\n",
    "        children = getChildren(nodeNum, dsi.numInternal)\n",
    "        leafNums = children - dsi.numInternal\n",
    "        pos,unlabeled = list(zip(*[getTransformScores(dsi,n) for n in leafNums]))\n",
    "        pos = np.concatenate(pos).reshape((-1,1))\n",
    "        unlabeled = np.concatenate(unlabeled).reshape((-1,1))\n",
    "        NEstimates = int(np.sum([dsi.leafN[l] for l in leafNums]))\n",
    "        dsi.treeAlphaHats[nodeNum],_ = getEsts(pos, unlabeled, NEstimates)\n",
    "\n",
    "    for leafNum in range(dsi.numLeaves):\n",
    "        nodeNum = leafNum + dsi.numInternal\n",
    "        dsi.treeAlphaHats[nodeNum] = dsi.alphaHats[leafNum]\n",
    "        dsi.mu[leafNum],dsi.sigma[nodeNum] = ss.norm.fit(dsi.treeAlphaHats[nodeNum])\n",
    "    \n",
    "    maes = [np.mean(np.abs(dsi.mu - dsi.trueAlphas.flatten()))]\n",
    "    lr = 0.001\n",
    "\n",
    "    gradNLL_mu = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,dsi.leafN),0)\n",
    "    gradNLL_sigma = grad(treeNegativeLogLikelihood(dsi.treeAlphaHats,dsi.leafN),1)\n",
    "    NIter= 5000\n",
    "    for i in tqdm(range(NIter),total=NIter):\n",
    "        if not i % 1500:\n",
    "            lr = lr * .5\n",
    "        deltaMu = gradNLL_mu(dsi.mu,dsi.sigma)\n",
    "        deltaSigma = gradNLL_sigma(dsi.mu,dsi.sigma)\n",
    "        dsi.mu = dsi.mu - lr * deltaMu\n",
    "        dsi.sigma = dsi.sigma - lr * deltaSigma\n",
    "        maes.append(np.mean(np.abs(dsi.mu - dsi.trueAlphas.flatten())))\n",
    "\n",
    "\n",
    "\n",
    "    absErrs[\"local\"].append(maes[0])\n",
    "    absErrs[\"likelihood\"].append(maes[-1])\n",
    "    absErrs[\"global\"].append(np.mean(np.abs(dsi.globalAlphaHats.mean() - dsi.trueAlphas.flatten())))\n",
    "\n",
    "    plt.plot(maes)\n",
    "    plt.hlines(absErrs[\"global\"][-1],0,len(maes),color=\"black\")\n",
    "    plt.title(fileName.split(\"/\")[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.globalAlphaHats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.curves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dsi.curves[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.alphaHats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.trueAlphas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in absErrs.items():\n",
    "    print(k, \"{:.3f}\".format(np.mean(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

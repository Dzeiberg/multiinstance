{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.gaussian_dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from scipy.stats import norm, uniform,dirichlet\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pdb as pdb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed, randint, random\n",
    "from sklearn.datasets import make_spd_matrix as spd\n",
    "from sklearn import metrics\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from types import SimpleNamespace as SN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class mixture:\n",
    "\n",
    "    def __init__(self, components, mixing_proportion):\n",
    "        self.comps = components\n",
    "        self.mixProp = mixing_proportion\n",
    "        # self.sigmoid = activations.sigmoid()\n",
    "\n",
    "    def pdf(self, x):\n",
    "        return np.sum((p * comp.pdf(x) for (comp, p) in zip(self.comps, self.mixProp)), axis=1)\n",
    "\n",
    "    def cdf(self, x):\n",
    "        return np.sum((p * comp.cdf(x) for (comp, p) in zip(self.comps, self.mixProp)), axis=1)\n",
    "\n",
    "    def rvs(self, size):\n",
    "        sizes = np.cast['int32'](np.floor(size * self.mixProp))\n",
    "        #pdb.set_trace()\n",
    "        delta = np.cast['int32'](size - np.sum(sizes))\n",
    "        ix = np.random.choice(np.size(self.mixProp), size=delta, p=self.mixProp)\n",
    "        for ii in ix:\n",
    "            sizes[ii] = sizes[ii] + 1\n",
    "        dim = np.size(self.comps[0].rvs(size=1))\n",
    "        x = np.empty([0, dim])\n",
    "        for (s, comp) in zip(sizes, self.comps):\n",
    "            new = comp.rvs(size=[s, 1])\n",
    "            if len(new.shape) == 1:\n",
    "                new = np.expand_dims(new,1)\n",
    "            x = np.concatenate((x,new), axis=0)\n",
    "        #pdb.set_trace()\n",
    "        return x\n",
    "\n",
    "    def rvsCompInfo(self, size):\n",
    "        sizes = np.cast['int32'](np.floor(size * self.mixProp))\n",
    "        #pdb.set_trace()\n",
    "        delta = np.cast['int32'](size - np.sum(sizes))\n",
    "        ix = np.random.choice(np.size(self.mixProp), size=delta, p=self.mixProp)\n",
    "        for ii in ix:\n",
    "            sizes[ii] = sizes[ii] + 1\n",
    "        dim = np.size(self.comps[0].rvs(size=1))\n",
    "        x = np.empty([0, dim])\n",
    "        y = np.empty([0, 1])\n",
    "        k = 0\n",
    "        for (s, comp) in zip(sizes, self.comps):\n",
    "            new = comp.rvs(size=[s, 1])\n",
    "            print(x.shape, new.shape)\n",
    "            x = np.concatenate((x, new), axis=0)\n",
    "            y = np.concatenate((y, np.zeros([s, 1]) + k), axis=0)\n",
    "            k = k + 1\n",
    "        #pdb.set_trace()\n",
    "        return x, y\n",
    "\n",
    "    def component_pdfs(self, x):\n",
    "        return (comp.pdf(x) for comp in self.comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, dist_p, dist_n, alpha, n_p, n_u, batch_size=1024):\n",
    "        self.dist_p = dist_p\n",
    "        self.dist_n = dist_n\n",
    "        self.alpha = alpha\n",
    "        self.n_p = n_p\n",
    "        self.n_u = n_u\n",
    "        self.n_up = np.cast['int32'](np.floor(n_u * alpha))\n",
    "        self.n_un = self.n_u - self.n_up\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    @classmethod\n",
    "    def _shuffle_in_unison(self, a, b):\n",
    "        p = np.random.permutation(len(a))\n",
    "        return a[p],b[p]\n",
    "        \n",
    "    def data_pos(self, n):\n",
    "        #pdb.set_trace()\n",
    "        return np.reshape(self.dist_p.rvs(size=n), newshape=(n, -1))\n",
    "\n",
    "\n",
    "    def data_neg(self, n):\n",
    "        return np.reshape(self.dist_n.rvs(size=n), newshape=(n, -1))\n",
    "\n",
    "    def data_pos_compInfo(self, n):\n",
    "        #pdb.set_trace()\n",
    "        x, c = self.dist_p.rvsCompInfo(size=n)\n",
    "        x = np.reshape(x, newshape=(n, -1))\n",
    "        return x, c\n",
    "\n",
    "    def data_neg_compInfo(self, n):\n",
    "        x, c = self.dist_n.rvsCompInfo(size=n)\n",
    "        x = np.reshape(x, newshape=(n, -1))\n",
    "        return x, c\n",
    "\n",
    "    def data_ul(self, n, alpha):\n",
    "        n_up = np.cast['int32'](np.floor(n * alpha))\n",
    "        n_un = n - n_up\n",
    "        x_up = self.data_pos(n_up)\n",
    "        x_un = self.data_neg(n_un)\n",
    "        x = np.concatenate((x_up, x_un), axis=0)\n",
    "        y = np.zeros([n, 1])\n",
    "        y[np.arange(x_up.shape[0]), 0] = 1\n",
    "        return x, y\n",
    "\n",
    "    def pu_data(self):\n",
    "        x_p = self.data_pos(self.n_p)\n",
    "        x_u, y_u = self.data_ul(self.n_u, self.alpha)\n",
    "        x_pu = np.concatenate((x_p, x_u), axis=0)\n",
    "        y_pu = np.zeros([x_pu.shape[0], 1])\n",
    "        y_pu[np.arange(self.n_p), 0] = 1\n",
    "        y_pn = np.concatenate((np.ones([self.n_p, 1]), y_u), axis=0)\n",
    "        # y_pn = y_pu\n",
    "        # y_pn[x_pu.size(0):(self.n_p - 1):-1, 0] = y_u\n",
    "        return x_pu, y_pu, y_pn\n",
    "        \n",
    "    def pn_data(self, n, alpha):\n",
    "        \"return x,y\"\n",
    "        x_p = self.data_pos(int(alpha*n))\n",
    "        x_n = self.data_neg(int((1-alpha)*n))\n",
    "        y_p = np.ones((len(x_p), 1))\n",
    "        y_n = np.zeros((len(x_n), 1))\n",
    "        x = np.vstack((x_p, x_n))\n",
    "        y = np.vstack((y_p, y_n))\n",
    "        x, y = self._shuffle_in_unison(x, y)\n",
    "        return x, y\n",
    "\n",
    "    def pn_data_compInfo(self, n, alpha):\n",
    "        x_p, c_p = self.data_pos_compInfo(int(alpha*n))\n",
    "        x_n, c_n = self.data_neg_compInfo(int((1-alpha)*n))\n",
    "        y_p = np.ones((len(x_p), 1))\n",
    "        y_n = np.zeros((len(x_n), 1))\n",
    "        x = np.vstack((x_p, x_n))\n",
    "        y = np.vstack((y_p, y_n))\n",
    "        c = np.vstack((c_p, c_n))\n",
    "        return x, y, c\n",
    "    \n",
    "    def dens_pos(self, x):\n",
    "        return self.dist_p.pdf(x)\n",
    "\n",
    "    def dens_neg(self, x):\n",
    "        return self.dist_n.pdf(x)\n",
    "\n",
    "    def dens_mix(self, x, a):\n",
    "        return a * self.dens_pos(x) + (1 - a) * self.dens_neg(x)\n",
    "\n",
    "    def pn_posterior(self, x, a):\n",
    "        return a * self.dens_pos(x) / self.dens_mix(x, a)\n",
    "\n",
    "    def pu_posterior(self, x):\n",
    "        c1 = self.n_p / (self.n_u + self.n_p)\n",
    "        c2 = (self.n_up + self.n_p) / (self.n_u + self.n_p)\n",
    "        return c1 * self.dens_pos(x) / self.dens_mix(x, c2)\n",
    "\n",
    "    def pn_posterior_sts(self, x):\n",
    "        c = (self.n_up + self.n_p) / (self.n_u + self.n_p)\n",
    "        return self.pn_posterior(x, c)\n",
    "\n",
    "    def pn_posterior_cc(self, x):\n",
    "        return self.pn_posterior(x, self.alpha)\n",
    "\n",
    "    def pn_posterior_balanced(self, x):\n",
    "        return self.pn_posterior(x, 0.5)\n",
    "\n",
    "\n",
    "class GaussianDG(DataGenerator):\n",
    "\n",
    "    def __init__(self, mu, sig, alpha, n_p, n_u, batch_size=1024):\n",
    "        dist_p = norm(loc=0, scale=1)\n",
    "        dist_n = norm(loc=mu, scale=sig)\n",
    "        super(GaussianDG, self).__init__(dist_p=dist_p, dist_n=dist_n, alpha=alpha, n_p=n_p, n_u=n_u, batch_size=batch_size)\n",
    "\n",
    "\n",
    "class UniformDG(DataGenerator):\n",
    "\n",
    "    def __init__(self, mu, sig, alpha, n_p, n_u, batch_size=1024):\n",
    "        dist_p = uniform(loc=0, scale=1)\n",
    "        dist_n = uniform(loc=mu, scale=sig)\n",
    "        super(UniformDG, self).__init__(dist_p=dist_p, dist_n=dist_n, alpha=alpha, n_p=n_p, n_u=n_u, batch_size=batch_size)\n",
    "\n",
    "\n",
    "class NormalMixDG(DataGenerator):\n",
    "\n",
    "    def __init__(self, mu_pos, sig_pos, p_pos, mu_neg, sig_neg, p_neg, alpha, n_pos, n_ul, batch_size = 1024):\n",
    "        components_pos = [norm(loc=mu, scale=sig) for (mu, sig) in zip(mu_pos, sig_pos)]\n",
    "        components_neg = [norm(loc=mu, scale=sig) for (mu, sig) in zip(mu_neg, sig_neg)]\n",
    "        dist_pos = mixture(components_pos, p_pos)\n",
    "        dist_neg = mixture(components_neg, p_neg)\n",
    "        super(NormalMixDG, self).__init__(dist_p=dist_pos, dist_n=dist_neg, alpha=alpha, n_p=n_pos, n_u=n_ul, batch_size=batch_size)\n",
    "\n",
    "\n",
    "class MVNormalMixDG(DataGenerator):\n",
    "\n",
    "    def __init__(self, mu_pos, sig_pos, p_pos, mu_neg, sig_neg, p_neg, alpha, n_pos, n_ul, batch_size = 1024):\n",
    "        self.components_pos = [mvn(mean=mu, cov=sig) for (mu, sig) in zip(mu_pos, sig_pos)]\n",
    "        self.components_neg = [mvn(mean=mu, cov=sig) for (mu, sig) in zip(mu_neg, sig_neg)]\n",
    "        dist_pos = mixture(self.components_pos, p_pos)\n",
    "        dist_neg = mixture(self.components_neg, p_neg)\n",
    "        super(MVNormalMixDG, self).__init__(dist_p=dist_pos, dist_n=dist_neg, alpha=alpha, n_p=n_pos, n_u=n_ul, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NormalMixRandomParameters:\n",
    "\n",
    "    def __init__(self, dim, max_comps):\n",
    "        self.dim = dim\n",
    "        self.max_comps = max_comps\n",
    "        self.n_comps_pos = randint(1, max_comps)\n",
    "        self.n_comps_neg = randint(1, max_comps)\n",
    "        self.mu_pos = [np.array([2 * random() - 1 for i in np.arange(dim)]) for j in np.arange(self.n_comps_pos)]\n",
    "        self.mu_neg = [np.array([2 * random() - 1 for i in np.arange(dim)]) for j in np.arange(self.n_comps_neg)]\n",
    "        self.sig_pos = [spd(dim) for j in np.arange(self.n_comps_pos)]\n",
    "        self.sig_neg = [spd(dim) for j in np.arange(self.n_comps_neg)]\n",
    "        self.p_pos = dirichlet(np.ones(self.n_comps_pos)).rvs([])\n",
    "        self.p_neg = dirichlet(np.ones(self.n_comps_neg)).rvs([])\n",
    "        self.alpha = random()\n",
    "\n",
    "    def computePNDataMetrics(self):\n",
    "        epsilon = 10 ** -7\n",
    "        n = 10000\n",
    "        _, x, y, pos, neg, dg = self.generatePNData(n, n)\n",
    "        posterior_pos = dg.pn_posterior_balanced(pos)\n",
    "        irreducibility = np.mean(np.cast['int32'](posterior_pos > 1-epsilon).flatten())\n",
    "        posterior_x = dg.pn_posterior_balanced(x)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, posterior_x)\n",
    "        aucpn = metrics.auc(fpr, tpr)\n",
    "        #pdb.set_trace()\n",
    "        return {'aucpn': aucpn, 'irreducibility': irreducibility}\n",
    "\n",
    "    def createDataGenerator(self, n_pos, n_ul):\n",
    "        dg = MVNormalMixDG(self.mu_pos, self.sig_pos, self.p_pos, self.mu_neg, self.sig_neg, self.p_neg, self.alpha,\n",
    "                         n_pos, n_ul)\n",
    "        return dg\n",
    "\n",
    "    def generatePNData(self, n_pos, n_neg):\n",
    "        dg = self.createDataGenerator(500, 2000)\n",
    "        pos = dg.data_pos(n_pos)\n",
    "        neg = dg.data_neg(n_neg)\n",
    "        y = np.concatenate((np.ones([n_pos, 1]), np.zeros([n_neg, 1])), axis=0)\n",
    "        x = np.concatenate((pos, neg), axis=0)\n",
    "        xy = np.concatenate((x, y), axis=1)\n",
    "        return xy, x, y, pos, neg, dg\n",
    "\n",
    "    def perturb2Irreducibility(self, irr_range):\n",
    "        metricsPN = self.computePNDataMetrics()\n",
    "        if irr_range[0] <= metricsPN['irreducibility'] <= irr_range[1]:\n",
    "            return\n",
    "        sigma_flag = random( ) > 0.5\n",
    "        if metricsPN['irreducibility'] < irr_range[0]:\n",
    "            if sigma_flag:\n",
    "                self.decrease_covar(irr_range)\n",
    "            else:\n",
    "                self.move_mean_out(irr_range)\n",
    "        else:\n",
    "            if sigma_flag:\n",
    "                self.increase_covar(irr_range)\n",
    "            else:\n",
    "                if self.equalMeans():\n",
    "                    self.alignCovar(irr_range)\n",
    "                else:\n",
    "                    self.move_mean_in(irr_range)\n",
    "        metricsPN = self.computePNDataMetrics()\n",
    "        if irr_range[0] <= metricsPN['irreducibility'] <= irr_range[1]:\n",
    "            return\n",
    "        else:\n",
    "            self.perturb2Irreducibility(irr_range)\n",
    "\n",
    "    def increase_covar(self, irr_range):\n",
    "        i_pos = randint(0, self.n_comps_pos - 1)\n",
    "        sig = self.sig_pos[i_pos]\n",
    "        sig_ratio = self.sigmaRatio(sig)\n",
    "        dim_float = np.cast['float32'](self.dim)\n",
    "        if all(sig_ratio <= 2):\n",
    "            up = 1.1\n",
    "            while up > 1.001:\n",
    "                self.sig_pos[i_pos] = up * sig\n",
    "                metricsPN = self.computePNDataMetrics()\n",
    "                if metricsPN['irreducibility'] < irr_range[0]:\n",
    "                    up = 1 + (up-1)/2\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def decrease_covar(self, irr_range):\n",
    "        i_pos = randint(0, self.n_comps_pos - 1)\n",
    "        sig = self.sig_pos[i_pos]\n",
    "        sig_ratio = self.sigmaRatio(sig)\n",
    "        dim_float = np.cast['float32'](self.dim)\n",
    "        if all(sig_ratio > 0.5):\n",
    "            up = 0.5\n",
    "            while up < .99:\n",
    "                self.sig_pos[i_pos] = up * sig\n",
    "                metricsPN = self.computePNDataMetrics( )\n",
    "                if metricsPN['irreducibility'] > irr_range[1]:\n",
    "                    up = 1 - (1 - up) / 2\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def move_mean_out(self, irr_range):\n",
    "        i_pos, _ = self.componentIrreducibilitySampling()\n",
    "        #pdb.set_trace()\n",
    "        mu_pos = self.mu_pos[i_pos]\n",
    "        i_neg, _ = self.closestNegComp(mu_pos)\n",
    "        mu_neg = self.mu_neg[i_neg]\n",
    "        delta = mu_pos - mu_neg\n",
    "        self.mu_pos[i_pos] = self.mu_pos[i_pos] + 0.1 * delta\n",
    "        metricsPN = self.computePNDataMetrics( )\n",
    "\n",
    "        if metricsPN['irreducibility'] > irr_range[1]:\n",
    "            k = 0\n",
    "            lower = self.mu_pos[i_pos] - delta\n",
    "            upper = self.mu_pos[i_pos]\n",
    "            while ((metricsPN['irreducibility'] > irr_range[1]) or (metricsPN['irreducibility'] < irr_range[0])) and (k < 5):\n",
    "                self.mu_pos[i_pos] =  (lower + upper)/2\n",
    "                metricsPN = self.computePNDataMetrics( )\n",
    "                if irr_range[0] <= metricsPN['irreducibility'] <= irr_range[1]:\n",
    "                    break\n",
    "                if metricsPN['irreducibility'] > irr_range[1]:\n",
    "                    upper = self.mu_pos[i_pos]\n",
    "                else:\n",
    "                    lower = self.mu_pos[i_pos]\n",
    "                k = k + 1\n",
    "\n",
    "    def move_mean_in(self, irr_range):\n",
    "        i_pos = randint(0, self.n_comps_pos - 1)\n",
    "        upper = self.mu_pos[i_pos]\n",
    "        i_neg, _ = self.closestNegComp(upper)\n",
    "        lower = self.mu_neg[i_neg]\n",
    "        metricsPN = self.computePNDataMetrics( )\n",
    "        k = 0\n",
    "        while (metricsPN['irreducibility'] > irr_range[1]) and (k < 5):\n",
    "            self.mu_pos[i_pos] = (lower + upper)/2\n",
    "            metricsPN = self.computePNDataMetrics( )\n",
    "            if irr_range[0] <= metricsPN['irreducibility'] <= irr_range[1]:\n",
    "                break\n",
    "            if metricsPN['irreducibility'] > irr_range[1]:\n",
    "                upper = self.mu_pos[i_pos]\n",
    "            else:\n",
    "                lower = self.mu_pos[i_pos]\n",
    "            k = k + 1\n",
    "\n",
    "    def align_covar(self, irr_range):\n",
    "        i_pos = randint(0, self.n_comps_pos - 1)\n",
    "        sig_pos = self.sig_pos[i_pos]\n",
    "        i_neg, _ = self.closestNegComp(self.mu_pos[i_pos])\n",
    "        sig_neg = self.sig_neg[i_neg]\n",
    "        metricsPN = self.computePNDataMetrics( )\n",
    "        k = 0\n",
    "        up = 1.0\n",
    "        low = 0.0\n",
    "        while (metricsPN['irreducibility'] > irr_range[1]) and (k < 5):\n",
    "            a = (up + low)/2.0\n",
    "            self.sig_pos[i_pos] = a * sig_pos + (1-a) * sig_neg\n",
    "            metricsPN = self.computePNDataMetrics( )\n",
    "            if irr_range[0] <= metricsPN['irreducibility'] <= irr_range[1]:\n",
    "                break\n",
    "            if metricsPN['irreducibility'] > irr_range[1]:\n",
    "                up = a\n",
    "            else:\n",
    "                low = a\n",
    "            k = k + 1\n",
    "\n",
    "    def equalMeans(self):\n",
    "        epsilon = 10**-1\n",
    "        ix_delta = [self.closestNegComp(mu) for mu in self.mu_pos]\n",
    "        ix_delta = list(zip(*ix_delta))\n",
    "        delta = ix_delta[1]\n",
    "        sum = np.sum(delta, axis=0)\n",
    "        return sum < epsilon\n",
    "\n",
    "    def closestNegComp(self, mean):\n",
    "        delta = np.array([np.sum((mean-mu)**2, axis=0) for mu in self.mu_neg])\n",
    "        ix = np.argmin(delta, axis=0)\n",
    "        return ix, delta[ix]\n",
    "\n",
    "    def sigmaRatio(self, sigma):\n",
    "        det = np.linalg.det(sigma)\n",
    "        return np.array([det/np.linalg.det(sig_neg) for sig_neg in self.sig_neg])\n",
    "\n",
    "\n",
    "    def componentIrreducibilitySampling(self):\n",
    "        dg = self.createDataGenerator(500, 2000)\n",
    "        comp_irr = [np.mean(dg.pn_posterior_balanced(comp.rvs(size=500)), axis=0) for comp in dg.components_pos]\n",
    "        comp_irr = np.array(comp_irr)\n",
    "        p = (1-comp_irr)/np.sum(1-comp_irr, axis=0)\n",
    "        ix = np.random.choice(self.n_comps_pos, 1, p=p)\n",
    "        ix = np.reshape(ix, newshape=())\n",
    "        return ix, comp_irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NormalMixParameters:\n",
    "\n",
    "    def __init__(self, dim, max_comps, quiet=False):\n",
    "        self.dim = dim\n",
    "        self.max_comps = max_comps\n",
    "        #self.n_comps_pos = randint(1, max_comps)\n",
    "        #self.n_comps_neg = randint(1, max_comps)\n",
    "        self.n_comps_pos = max_comps\n",
    "        self.n_comps_neg = max_comps\n",
    "        self.mu_pos = list()\n",
    "        self.mu_neg = list()\n",
    "        for i in np.arange(max(self.n_comps_pos, self.n_comps_neg)):\n",
    "            mu = np.array([16/np.sqrt(self.dim) * random() - 8/np.sqrt(self.dim) for i in np.arange(self.dim)])\n",
    "            if i < self.n_comps_pos:\n",
    "                self.mu_pos.append(mu)\n",
    "            if i < self.n_comps_neg:\n",
    "                self.mu_neg.append(mu)\n",
    "        #self.mu_pos = [np.zeros(dim) for j in np.arange(self.n_comps_pos)]\n",
    "        #self.mu_neg = [np.zeros(dim) for j in np.arange(self.n_comps_neg)]\n",
    "        self.sig_pos = [np.identity(dim) for j in np.arange(self.n_comps_pos)]\n",
    "        self.sig_neg = [np.identity(dim) for j in np.arange(self.n_comps_neg)]\n",
    "        self.p_pos = dirichlet(np.ones(self.n_comps_pos)).rvs([])\n",
    "        #self.p_neg = dirichlet(np.ones(self.n_comps_neg)).rvs([])\n",
    "        self.p_neg = self.p_pos\n",
    "        #self.changeInfo = {'changed': False, 'positive': True, 'mu': True, 'ix':0, 'oldvalue': self.mu_pos[0]}\n",
    "        self.changeInfo = {'changed': False}\n",
    "        self.alpha = random()\n",
    "        self.quiet = quiet\n",
    "\n",
    "    def computePNDataMetrics(self):\n",
    "        epsilon = 0.05\n",
    "        n = 10000\n",
    "        _, x, y, pos, neg, dg = self.generatePNData(n, n)\n",
    "        posterior_pos = dg.pn_posterior_balanced(pos)\n",
    "        irreducibility = np.mean(np.cast['int32'](posterior_pos > 1-epsilon).flatten())\n",
    "        posterior_x = dg.pn_posterior_balanced(x)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, posterior_x)\n",
    "        aucpn = metrics.auc(fpr, tpr)\n",
    "        #pdb.set_trace()\n",
    "        return {'aucpn': aucpn, 'irreducibility': irreducibility}\n",
    "\n",
    "    def createDataGenerator(self, n_pos, n_ul):\n",
    "        dg = MVNormalMixDG(self.mu_pos, self.sig_pos, self.p_pos, self.mu_neg, self.sig_neg, self.p_neg, self.alpha,\n",
    "                         n_pos, n_ul)\n",
    "        return dg\n",
    "\n",
    "    def generatePNData(self, n_pos, n_neg):\n",
    "        dg = self.createDataGenerator(50, 500)\n",
    "        pos = dg.data_pos(n_pos)\n",
    "        neg = dg.data_neg(n_neg)\n",
    "        y = np.concatenate((np.ones([n_pos, 1]), np.zeros([n_neg, 1])), axis=0)\n",
    "        x = np.concatenate((pos, neg), axis=0)\n",
    "        xy = np.concatenate((x, y), axis=1)\n",
    "        #pdb.set_trace()\n",
    "        return xy, x, y, pos, neg, dg\n",
    "\n",
    "    def perturb2SatisfyMetrics(self, irr_range, aucpn_range):\n",
    "        irr_mid = np.mean(irr_range, axis=0)\n",
    "        aucpn_min = min_aucpn(irr_mid)\n",
    "        # if aucpn_range[0] < aucpn_min:\n",
    "        #    raise ValueError('Irreducibility range and AUCPN range are not compatible:\\n',\n",
    "        #                      'AUCPN should be above', aucpn_min, 'for midpoint irreducibility of', irr_mid)\n",
    "        while not self.isMetricSatisfied(irr_range, aucpn_range):\n",
    "            self.markRandomParForChange()\n",
    "            #print(self.changeInfo)\n",
    "            if self.muMarked():\n",
    "                self.perturbMu(irr_range, aucpn_range)\n",
    "            else:\n",
    "                if self.pMarked():\n",
    "                    self.perturbProportion(irr_range, aucpn_range)\n",
    "                else:\n",
    "                    if random() <= 1:\n",
    "                        self.perturbSigmaShape(irr_range, aucpn_range)\n",
    "                    else:\n",
    "                        self.perturbSigmaScale(irr_range, aucpn_range)\n",
    "            self.commitChange()\n",
    "\n",
    "    def perturbMu(self, irr_range, aucpn_range):\n",
    "        if not self.quiet:\n",
    "            print('Mu Perturb')\n",
    "        c = 0.1\n",
    "        delta = np.array([2 * random( ) - 1 for i in np.arange(self.dim)])\n",
    "        delta = c * delta/np.linalg.norm(delta)\n",
    "        mu = self.getMarkedParOldValue()\n",
    "        up = 1.0\n",
    "        self.proposeChange(mu + up * delta)\n",
    "        while not self.isMetricUBSatisfied(irr_range, aucpn_range):\n",
    "            up = up/2\n",
    "            self.proposeChange(mu + up * delta)\n",
    "\n",
    "    def perturbSigmaShape(self, irr_range, aucpn_range):\n",
    "        if not self.quiet:\n",
    "            print('Sigma Shape Perturb')\n",
    "        newsigma = spd(self.dim)\n",
    "        sigma = self.getMarkedParOldValue()\n",
    "        a = 0.1\n",
    "        self.proposeChange((1-a) * sigma + a * newsigma)\n",
    "        while not self.isMetricUBSatisfied(irr_range, aucpn_range):\n",
    "            a = a/2\n",
    "            self.proposeChange((1-a) * sigma + a * newsigma)\n",
    "\n",
    "    def perturbSigmaScale(self, irr_range, aucpn_range):\n",
    "        if not self.quiet:\n",
    "            print('Sigma Scale Perturb')\n",
    "        sigma = self.getMarkedParOldValue()\n",
    "        a = 1.5\n",
    "        self.proposeChange(a * sigma)\n",
    "        while not (self.isMetricUBSatisfied(irr_range, aucpn_range) and self.acceptableSigma(a * sigma)):\n",
    "            a = 1 + (a - 1)/2\n",
    "            #print(a)\n",
    "            #print('metric:', self.isMetricUBSatisfied(irr_range, aucpn_range))\n",
    "            #print('acceptable Sigma:', self.acceptableSigma(a * sigma) )\n",
    "            self.proposeChange(a * sigma)\n",
    "\n",
    "    def perturbProportion(self, irr_range, aucpn_range):\n",
    "        if not self.quiet:\n",
    "            print('Perturb Proportion')\n",
    "        prop = self.getMarkedParOldValue( )\n",
    "        a = 0.25\n",
    "        if self.changeInfo['is_positive']:\n",
    "            prop_1 = dirichlet(np.ones(self.n_comps_pos)).rvs([])\n",
    "        else:\n",
    "            prop_1 = dirichlet(np.ones(self.n_comps_neg)).rvs([])\n",
    "        new_prop = (1 - a) * prop + a * prop_1\n",
    "        self.proposeChange(new_prop)\n",
    "        while not (self.isMetricUBSatisfied(irr_range, aucpn_range)):\n",
    "            a = a/2\n",
    "            new_prop = (1 - a) * prop + a * prop_1\n",
    "            # print(a)\n",
    "            self.proposeChange(new_prop)\n",
    "\n",
    "    def muMarked(self):\n",
    "        return self.changeInfo['is_mu']\n",
    "\n",
    "    def pMarked(self):\n",
    "        return self.changeInfo['is_proportion']\n",
    "\n",
    "    def acceptableSigma(self, sigma):\n",
    "        det = np.linalg.det(sigma)\n",
    "        ratios = np.array([det/np.linalg.det(sig) for sig in self.sig_pos + self.sig_neg])\n",
    "        if not self.quiet:\n",
    "            print(ratios)\n",
    "        ratios[:] = 1\n",
    "        return all(ratios > 0.25)\n",
    "\n",
    "    def isMetricSatisfied(self, irr_range, aucpn_range):\n",
    "        metrics = self.computePNDataMetrics()\n",
    "        irr_satisfied = irr_range[0] <= metrics['irreducibility'] <= irr_range[1]\n",
    "        auc_satisfied = aucpn_range[0] <= metrics['aucpn'] <= aucpn_range[1]\n",
    "        if not self.quiet:\n",
    "            print(metrics)\n",
    "        return irr_satisfied and auc_satisfied\n",
    "\n",
    "    def isMetricUBSatisfied(self, irr_range, aucpn_range):\n",
    "        metrics = self.computePNDataMetrics()\n",
    "        irr_satisfied = metrics['irreducibility'] <= irr_range[1]\n",
    "        auc_satisfied = metrics['aucpn'] <= aucpn_range[1]\n",
    "        return irr_satisfied and auc_satisfied\n",
    "\n",
    "    def proposeChange(self, newValue):\n",
    "        self.changeInfo['changed'] = True\n",
    "        V = SN(**self.changeInfo)\n",
    "        self.updatePar(V.is_positive, V.is_mu, V.is_proportion, V.ix, newValue)\n",
    "\n",
    "    def commitChange(self):\n",
    "        self.changeInfo = {'changed': False}\n",
    "\n",
    "    def updatePar(self, is_positive, is_mu, is_proportion, ix, newValue):\n",
    "        if is_positive:\n",
    "            if is_mu:\n",
    "                self.mu_pos[ix] = newValue\n",
    "            else:\n",
    "                if is_proportion:\n",
    "                    self.p_pos = newValue\n",
    "                else:\n",
    "                    self.sig_pos[ix] = newValue\n",
    "        else:\n",
    "            if is_mu:\n",
    "                self.mu_neg[ix] = newValue\n",
    "            else:\n",
    "                if is_proportion:\n",
    "                    self.p_neg = newValue\n",
    "                else:\n",
    "                    self.sig_neg[ix] = newValue\n",
    "\n",
    "    def markRandomParForChange(self):\n",
    "        if self.changeInfo['changed']:\n",
    "            raise ValueError('Attempting to change a new parameter before committing the previous one')\n",
    "        is_positive = random() < 0.5\n",
    "        rr = random()\n",
    "        is_mu = rr < 1.0/3.0\n",
    "        is_proportion = 1.0/3.0 <= rr <= 2.0/3.0\n",
    "        ix = np.nan\n",
    "        if is_positive:\n",
    "            ix = randint(0, self.n_comps_pos - 1)\n",
    "            if is_mu:\n",
    "                value = self.mu_pos[ix]\n",
    "            else:\n",
    "                if is_proportion:\n",
    "                    value = self.p_pos\n",
    "                else:\n",
    "                    value = self.sig_pos[ix]\n",
    "        else:\n",
    "            ix = randint(0, self.n_comps_neg - 1)\n",
    "            if is_mu:\n",
    "                value = self.mu_neg[ix]\n",
    "            else:\n",
    "                if is_proportion:\n",
    "                    value = self.p_neg\n",
    "                else:\n",
    "                    value = self.sig_neg[ix]\n",
    "\n",
    "        self.changeInfo.update({'is_positive': is_positive, 'is_mu': is_mu, 'is_proportion': is_proportion, 'ix': ix, 'oldValue': value})\n",
    "\n",
    "    def getMarkedParOldValue(self):\n",
    "        return self.changeInfo['oldValue']\n",
    "\n",
    "    def revert2OldValue(self):\n",
    "        V = SN(**self.changeInfo)\n",
    "        self.updatePar(V.is_positive, V.is_mu, V.ix, V.oldValue)\n",
    "        self.changeInfo['changed'] = False\n",
    "        return\n",
    "\n",
    "def min_aucpn(irreducibility):\n",
    "    return irreducibility + (1-irreducibility)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GaussianMixtureDataGenerator(dim, n_comps, aucpn_range, n_p, n_u, irreducibility_range=[0.1,1]):\n",
    "    NMix = NormalMixParameters(dim, n_comps,quiet=True)\n",
    "    NMix.perturb2SatisfyMetrics(irreducibility_range, aucpn_range)\n",
    "    dg = NMix.createDataGenerator(n_p, n_u)\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dim = 10\n",
    "n_comps = 5\n",
    "aucpn_range = [0.5, 0.85]\n",
    "n_p = 5000\n",
    "n_u = 20000\n",
    "dg = GaussianMixtureDataGenerator(dim, n_comps, aucpn_range, n_p, n_u)\n",
    "x, y, y_p = dg.pu_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 10), (25000, 1), (25000, 1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

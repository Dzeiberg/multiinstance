{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:14:13.588497Z",
     "start_time": "2021-02-08T18:14:13.584730Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp agglomerative_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:14:28.127525Z",
     "start_time": "2021-02-08T18:14:23.087091Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.distanceApproaches import *\n",
    "from multiinstance.data.syntheticData import buildDataset,getBag\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:32:46.063041Z",
     "start_time": "2021-02-08T18:32:46.058718Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import set_num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:35:52.108574Z",
     "start_time": "2021-02-08T20:35:52.106225Z"
    }
   },
   "outputs": [],
   "source": [
    "set_num_threads(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T13:13:40.139217Z",
     "start_time": "2021-02-09T13:13:40.112918Z"
    }
   },
   "outputs": [],
   "source": [
    "getEsts??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T12:46:07.237525Z",
     "start_time": "2021-02-09T12:46:07.201462Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class AgglomerativeClustering:\n",
    "    def __init__(self, dsi, kstest_alpha):\n",
    "        self.clusterMembers = {i:[i] for i in range(dsi.N)}\n",
    "        self.clusterAlphaHats = {i: dsi.alphaHats[i] for i in range(dsi.N)}\n",
    "        self.clusterCurves = {i: dsi.curves[i] for i in range(dsi.N)}\n",
    "        self.ds = dsi\n",
    "        self.log = []\n",
    "        self.meanAbsErrs = []\n",
    "        self.bagEstimateVariances = []\n",
    "        self.kstest_alpha = kstest_alpha\n",
    "        self.nummerges = 0\n",
    "\n",
    "    def clusteringIteration(self):\n",
    "        # track whether any new clusters are merged, indicating this new cluster might not have\n",
    "        # been compared to other clusters and a new iteration is needed to do so\n",
    "        nextIterNeeded=False\n",
    "        clusters = list(self.clusterMembers.keys())\n",
    "        np.random.shuffle(clusters)\n",
    "        for ci in tqdm(clusters, leave=False, desc=\"clustering iteration\"):\n",
    "            # might have to skip iteration if this cluster was merged elsewhere in a previous for loop iter\n",
    "            if ci in self.clusterMembers.keys():\n",
    "                \n",
    "                # merging candidates are other remaining clusters\n",
    "                candidates = list(set(self.clusterMembers.keys()) - {ci})\n",
    "                np.random.shuffle(candidates)\n",
    "                for cj in candidates:\n",
    "                    # get current one-dimensional scores for all unlabeled instances in all bags in this cluster\n",
    "                    scores_i = np.concatenate(tuple([getTransformScores(self.ds,b)[1] for b in self.clusterMembers[ci]]))\n",
    "                    # get scores for merge candidate cluster\n",
    "                    scores_j = np.concatenate([getTransformScores(self.ds,b)[1] for b in self.clusterMembers[cj]])\n",
    "                    # 2-sided kolmogrov-smirnov test (H0: samples from same distribution)\n",
    "                    stat,p = ss.ks_2samp(scores_i.tolist(),scores_j.tolist())\n",
    "                    # if you fail to reject, merge samples\n",
    "                    if p > self.kstest_alpha:\n",
    "                        self.nummerges += 1\n",
    "                        nextIterNeeded=True\n",
    "                        # add this merge to the log\n",
    "                        self.log.append((ci,cj, p))\n",
    "                        # perform the actual merge\n",
    "                        self.clusterMembers[ci] = self.clusterMembers[ci] + self.clusterMembers.pop(cj)\n",
    "                        # track the within-bag class prior variance at each clustering iteration\n",
    "                        self.doLogging()\n",
    "        return nextIterNeeded\n",
    "    \n",
    "    def alphaclusteringIteration(self):\n",
    "        # track whether any new clusters are merged, indicating this new cluster might not have\n",
    "        # been compared to other clusters and a new iteration is needed to do so\n",
    "        nextIterNeeded=False\n",
    "        clusters = list(self.clusterMembers.keys())\n",
    "        np.random.shuffle(clusters)\n",
    "        for ci in tqdm(clusters, leave=False, desc=\"clustering iteration\"):\n",
    "            # might have to skip iteration if this cluster was merged elsewhere in a previous for loop iter\n",
    "            if ci in self.clusterMembers.keys():\n",
    "                \n",
    "                # merging candidates are other remaining clusters\n",
    "                candidates = list(set(self.clusterMembers.keys()) - {ci})\n",
    "                np.random.shuffle(candidates)\n",
    "                for cj in tqdm(candidates,total=len(candidateses),desc=\"candidates\",leave=False):\n",
    "                    # use the alpha hat estimates for each bag as the samples for the test\n",
    "                    scores_i = self.clusterAlphaHats[ci]\n",
    "                    scores_j = self.clusterAlphaHats[cj]\n",
    "                    # 2-sided kolmogrov-smirnov test (H0: samples from same distribution)\n",
    "                    stat,p = ss.ks_2samp(scores_i.tolist(),scores_j.tolist())\n",
    "                    # if you fail to reject, merge samples\n",
    "                    if p > self.kstest_alpha:\n",
    "                        nextIterNeeded=True\n",
    "                        # add this merge to the log\n",
    "                        self.log.append((ci,cj, p))\n",
    "                        # perform the actual merge\n",
    "                        self.clusterMembers[ci] = self.clusterMembers[ci] + self.clusterMembers.pop(cj)\n",
    "                        # track the within-bag class prior variance at each clustering iteration\n",
    "                        self.doLogging()\n",
    "        return nextIterNeeded\n",
    "        \n",
    "    def doLogging(self):\n",
    "        absErrs = []\n",
    "        bagEstVar = 0\n",
    "        aes = 0\n",
    "        \n",
    "        for bagNum,bags in self.clusterMembers.items():\n",
    "            # Get cluster estimate\n",
    "            if len(bags) > 1:\n",
    "                P, _ = list(zip(*[self.ds.getBag(int(i)) for i in range(self.ds.N)]))\n",
    "                _,U = list(zip(*[self.ds.getBag(b) for b in bags]))\n",
    "                p = np.concatenate(P)\n",
    "                u = np.concatenate(U)\n",
    "                alphaHats, curves = getEsts(p,u,10)\n",
    "                clusterAlphaHat = np.mean(alphaHats)\n",
    "                self.clusterAlphaHats[bagNum] = alphaHats\n",
    "                self.clusterCurves[bagNum] = curves\n",
    "                clusterAlphas = self.ds.trueAlphas[bags].flatten()\n",
    "            else:\n",
    "                clusterAlphaHat = self.ds.alphaHats[bags].mean(1)\n",
    "                clusterAlphas = self.ds.trueAlphas[bags].flatten()\n",
    "            absErrs.append(np.abs(clusterAlphaHat - clusterAlphas))\n",
    "            # Get the true and predicted alphas for each bag in this cluster\n",
    "            bagsAlphaHat = self.ds.alphaHats[bags].reshape((len(bags),-1)).mean(1)\n",
    "            # log abs. err for this cluster\n",
    "            # add to calculation for variance in estimates for this cluster\n",
    "            bagEstVar += np.sum((bagsAlphaHat - clusterAlphaHat)**2)\n",
    "        self.meanAbsErrs.append(np.mean(np.concatenate(absErrs)))\n",
    "        self.bagEstimateVariances.append(bagEstVar / (self.ds.N - 1))\n",
    "\n",
    "    def cluster(self):\n",
    "        self.doLogging()\n",
    "        nextIterNeeded = self.clusteringIteration()\n",
    "        while nextIterNeeded:\n",
    "            nextIterNeeded = self.clusteringIteration()\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:27:32.269176Z",
     "start_time": "2021-02-08T20:27:32.253198Z"
    }
   },
   "outputs": [],
   "source": [
    "def exp():\n",
    "    dsi = buildDataset(100,alphaDistr=lambda: np.random.uniform(.2,.5),\n",
    "                      nP=5,nU=10)\n",
    "\n",
    "    dsi = addTransformScores(dsi)\n",
    "\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)\n",
    "    alphas = [0.5, 0.65, 0.75,0.85, 0.95]\n",
    "    aggs = []\n",
    "    for alpha in tqdm(alphas,desc=\"alphas\"):\n",
    "        print(\"alpha = {}\".format(alpha))\n",
    "        agg0 = AgglomerativeClustering(dsi, alpha)\n",
    "        agg0.cluster()\n",
    "        aggs.append(agg0)\n",
    "    return alphas, aggs\n",
    "\n",
    "def makeFig(alphas, aggs):\n",
    "    fig,ax = plt.subplots(1,len(aggs), figsize=(16,4),sharey=True)\n",
    "    for r in range(len(aggs)):\n",
    "        ax[r].plot(aggs[r].meanAbsErrs, label=r\"\\alpha = \"+str(alphas[r]))\n",
    "        ax[r].set_title(r\"$\\alpha$: \"+str(alphas[r]))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-09T13:26:03.378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='getting bag estimates', max=500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767fe8ddf5534421829d22780f914710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='clustering iteration', max=500.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsi = buildDataset(500,alphaDistr=lambda: np.random.uniform(.1,.5))\n",
    "\n",
    "dsi = addTransformScores(dsi)\n",
    "\n",
    "dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)\n",
    "\n",
    "agg0 = AgglomerativeClustering(dsi, .5)\n",
    "agg0.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-09T13:26:03.842Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(agg0.meanAbsErrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-09T13:26:04.218Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,bags in agg0.clusterMembers.items():\n",
    "    j = np.random.randint(0,high=10)\n",
    "    c = agg0.clusterCurves[i][j]\n",
    "    # plot a curve for this cluster\n",
    "    plt.plot(np.arange(0,1,.01),(c - c.min()) / (c.max() - c.min()))\n",
    "    # plot the estimates for this curve\n",
    "    plt.vlines(agg0.clusterAlphaHats[i][j],0,1,color=\"red\",label=r\"$\\hat{\\alpha}$\")\n",
    "    # plot true alphas for each bag\n",
    "    nPs = np.array([agg0.ds.numP[b] for b in bags])\n",
    "    nUs = np.array([agg0.ds.numU[b] for b in bags])\n",
    "    plt.vlines([agg0.ds.trueAlphas[b] for b in bags],\n",
    "               np.zeros(len(bags)), nPs/nPs.sum(), color=\"black\", label=r\"$\\alpha$\")\n",
    "    plt.title(\"num bags: {}    numP: {}    numU: {}\".format(len(bags),\n",
    "                                                        nPs.sum(),\n",
    "                                                        nUs.sum()))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agglomerative_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from multiinstance.utils import *\n",
    "from multiinstance.distanceApproaches import *\n",
    "from multiinstance.data.syntheticData import buildDataset,getBag\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import set_num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_num_threads(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AgglomerativeClustering:\n",
    "    def __init__(self, dsi, kstest_alpha):\n",
    "        self.clusterMembers = {i:[i] for i in range(dsi.N)}\n",
    "        self.clusterAlphaHats = {i: dsi.alphaHats[i] for i in range(dsi.N)}\n",
    "        self.ds = dsi\n",
    "        self.log = []\n",
    "        self.meanAbsErrs = []\n",
    "        self.bagEstimateVariances = []\n",
    "        self.kstest_alpha = kstest_alpha\n",
    "        self.nummerges = 0\n",
    "\n",
    "    def clusteringIteration(self):\n",
    "        # track whether any new clusters are merged, indicating this new cluster might not have\n",
    "        # been compared to other clusters and a new iteration is needed to do so\n",
    "        nextIterNeeded=False\n",
    "        clusters = list(self.clusterMembers.keys())\n",
    "        np.random.shuffle(clusters)\n",
    "        for ci in tqdm(clusters, leave=False, desc=\"clustering iteration\"):\n",
    "            # might have to skip iteration if this cluster was merged elsewhere in a previous for loop iter\n",
    "            if ci in self.clusterMembers.keys():\n",
    "                \n",
    "                # merging candidates are other remaining clusters\n",
    "                candidates = list(set(self.clusterMembers.keys()) - {ci})\n",
    "                np.random.shuffle(candidates)\n",
    "                for cj in candidates:\n",
    "                    # get current one-dimensional scores for all unlabeled instances in all bags in this cluster\n",
    "                    scores_i = np.concatenate(tuple([getTransformScores(self.ds,b)[1] for b in self.clusterMembers[ci]]))\n",
    "                    # get scores for merge candidate cluster\n",
    "                    scores_j = np.concatenate([getTransformScores(self.ds,b)[1] for b in self.clusterMembers[cj]])\n",
    "                    # 2-sided kolmogrov-smirnov test (H0: samples from same distribution)\n",
    "                    stat,p = ss.ks_2samp(scores_i.tolist(),scores_j.tolist())\n",
    "                    # if you fail to reject, merge samples\n",
    "                    if p > self.kstest_alpha:\n",
    "                        self.nummerges += 1\n",
    "                        nextIterNeeded=True\n",
    "                        # add this merge to the log\n",
    "                        self.log.append((ci,cj, p))\n",
    "                        # perform the actual merge\n",
    "                        self.clusterMembers[ci] = self.clusterMembers[ci] + self.clusterMembers.pop(cj)\n",
    "                        # track the within-bag class prior variance at each clustering iteration\n",
    "                        self.doLogging()\n",
    "        return nextIterNeeded\n",
    "    \n",
    "    def alphaclusteringIteration(self):\n",
    "        # track whether any new clusters are merged, indicating this new cluster might not have\n",
    "        # been compared to other clusters and a new iteration is needed to do so\n",
    "        nextIterNeeded=False\n",
    "        clusters = list(self.clusterMembers.keys())\n",
    "        np.random.shuffle(clusters)\n",
    "        for ci in tqdm(clusters, leave=False, desc=\"clustering iteration\"):\n",
    "            # might have to skip iteration if this cluster was merged elsewhere in a previous for loop iter\n",
    "            if ci in self.clusterMembers.keys():\n",
    "                \n",
    "                # merging candidates are other remaining clusters\n",
    "                candidates = list(set(self.clusterMembers.keys()) - {ci})\n",
    "                np.random.shuffle(candidates)\n",
    "                for cj in tqdm(candidates,total=len(candidateses),desc=\"candidates\",leave=False):\n",
    "                    # use the alpha hat estimates for each bag as the samples for the test\n",
    "                    scores_i = self.clusterAlphaHats[ci]\n",
    "                    scores_j = self.clusterAlphaHats[cj]\n",
    "                    # 2-sided kolmogrov-smirnov test (H0: samples from same distribution)\n",
    "                    stat,p = ss.ks_2samp(scores_i.tolist(),scores_j.tolist())\n",
    "                    # if you fail to reject, merge samples\n",
    "                    if p > self.kstest_alpha:\n",
    "                        nextIterNeeded=True\n",
    "                        # add this merge to the log\n",
    "                        self.log.append((ci,cj, p))\n",
    "                        # perform the actual merge\n",
    "                        self.clusterMembers[ci] = self.clusterMembers[ci] + self.clusterMembers.pop(cj)\n",
    "                        # track the within-bag class prior variance at each clustering iteration\n",
    "                        self.doLogging()\n",
    "        return nextIterNeeded\n",
    "        \n",
    "    def doLogging(self):\n",
    "        absErrs = []\n",
    "        bagEstVar = 0\n",
    "        aes = 0\n",
    "        \n",
    "        for bagNum,bags in self.clusterMembers.items():\n",
    "            # Get cluster estimate\n",
    "            if len(bags) > 1:\n",
    "                P,U = list(zip(*[self.ds.getBag(b) for b in bags]))\n",
    "                p = np.concatenate(P)\n",
    "                u = np.concatenate(U)\n",
    "                alphaHats, _ = getEsts(p,u,10)\n",
    "                clusterAlphaHat = np.mean(alphaHats)\n",
    "                self.clusterAlphaHats[bagNum] = alphaHats\n",
    "                clusterAlphas = self.ds.trueAlphas[bags].flatten()\n",
    "            else:\n",
    "                clusterAlphaHat = self.ds.alphaHats[bags].mean(1)\n",
    "                clusterAlphas = self.ds.trueAlphas[bags].flatten()\n",
    "            absErrs.append(np.abs(clusterAlphaHat - clusterAlphas))\n",
    "            # Get the true and predicted alphas for each bag in this cluster\n",
    "            bagsAlphaHat = self.ds.alphaHats[bags].reshape((len(bags),-1)).mean(1)\n",
    "            # log abs. err for this cluster\n",
    "            # add to calculation for variance in estimates for this cluster\n",
    "            bagEstVar += np.sum((bagsAlphaHat - clusterAlphaHat)**2)\n",
    "        self.meanAbsErrs.append(np.mean(np.concatenate(absErrs)))\n",
    "        self.bagEstimateVariances.append(bagEstVar / (self.ds.N - 1))\n",
    "\n",
    "    def cluster(self):\n",
    "        self.doLogging()\n",
    "        nextIterNeeded = self.clusteringIteration()\n",
    "        while nextIterNeeded:\n",
    "            nextIterNeeded = self.clusteringIteration()\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi = buildDataset(100,alphaDistr=lambda: np.random.uniform(.01,.25),\n",
    "                      nP=5,nU=15)\n",
    "\n",
    "dsi = addTransformScores(dsi)\n",
    "\n",
    "dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg0 = AgglomerativeClustering(dsi, .75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg0.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agg0.meanAbsErrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp():\n",
    "    dsi = buildDataset(100,alphaDistr=lambda: np.random.uniform(.01,.25),\n",
    "                      nP=5,nU=10)\n",
    "\n",
    "    dsi = addTransformScores(dsi)\n",
    "\n",
    "    dsi.alphaHats,dsi.curves = getBagAlphaHats(dsi,numbootstraps=10)\n",
    "    alphas = [0.5, 0.65, 0.75,0.85, 0.95]\n",
    "    aggs = []\n",
    "    for alpha in tqdm(alphas,desc=\"alphas\"):\n",
    "        print(\"alpha = {}\".format(alpha))\n",
    "        agg0 = AgglomerativeClustering(dsi, alpha)\n",
    "        agg0.cluster()\n",
    "        aggs.append(agg0)\n",
    "    return alphas, aggs\n",
    "\n",
    "def makeFig(alphas, aggs):\n",
    "    fig,ax = plt.subplots(1,len(aggs), figsize=(16,4),sharey=True)\n",
    "    for r in range(len(aggs)):\n",
    "        ax[r].plot(aggs[r].meanAbsErrs, label=r\"\\alpha = \"+str(alphas[r]))\n",
    "        ax[r].set_title(r\"$\\alpha$: \"+str(alphas[r]))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in tqdm(range(10)):\n",
    "    alphas2, aggs2 = exp()\n",
    "\n",
    "    fig = makeFig(alphas2, aggs2)\n",
    "    plt.savefig(\"figs/nb_06/fig_{}.pdf\".format(rep),\n",
    "                format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* want many clusters with small $\\alpha$ variance\n",
    "* don't want to merge a bag large enough to have low variance in estimations\n",
    "* two ways of estimating cluster similarity\n",
    "    * similarity in transform scores\n",
    "        * KS-test has critical value hyperparameter\n",
    "        * wasserstein distance has distance cutoff hyperparameter\n",
    "    * similarity in estimates from distcurve\n",
    "        * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
